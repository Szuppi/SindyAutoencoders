Code:

num_experiments = 9
df = pd.DataFrame()
warnings.filterwarnings("ignore")
for i in range(num_experiments):
    print('EXPERIMENT %d' % i)

    # ---- set seeds for this experiment ----
    seed = BASE_SEED + i + 3 + 2 + 2 + 5
    random.seed(seed)
    np.random.seed(seed)
    tf.set_random_seed(seed)  #tf.compat.v1.set_random_seed(seed)
    # ---------------------------------------

    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))

    params['save_name'] = f'lorenz_seed{seed}_' + datetime.datetime.now().strftime("%Y_%m_%d_%H_%M_%S_%f")

    tf.reset_default_graph()

    results_dict = train_network(training_data, validation_data, params)
    df = df.append({**results_dict, **params}, ignore_index=True)

df.to_pickle('experiment_results_' + datetime.datetime.now().strftime("%Y%m%d%H%M") + '.pkl')

------------------------------------------------------------------------------------------------------------------

Output:


EXPERIMENT 0
WARNING:tensorflow:From C:\Users\local_user\AppData\Local\Temp\ipykernel_29664\811575834.py:11: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From C:\Users\local_user\AppData\Local\Temp\ipykernel_29664\811575834.py:18: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src\autoencoder.py:28: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src\autoencoder.py:194: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src\training.py:12: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From c:\Users\local_user\anaconda3\envs\tf1-sindy\lib\site-packages\tensorflow_core\python\ops\math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src\training.py:14: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src\training.py:14: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From ../../src\training.py:14: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

TRAINING
WARNING:tensorflow:From ../../src\training.py:28: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From ../../src\training.py:29: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

Epoch 0
   training loss 0.025690220296382904, (0.025245927, 146.2193, 4.35872, 0.84202135)
   validation loss 0.04018391668796539, (0.03896275, 175.92577, 12.127464, 0.84202135)
decoder loss ratio: 0.210392, decoder SINDy loss  ratio: 0.998604
Epoch 100
   training loss 9.397116809850559e-05, (6.672408e-05, 0.11649076, 0.06595931, 2.0651152)
   validation loss 0.0001409557298757136, (9.152977e-05, 0.5337491, 0.28774816, 2.0651152)
decoder loss ratio: 0.000494, decoder SINDy loss  ratio: 0.023694
Epoch 200
   training loss 3.886797640006989e-05, (1.7094797e-05, 0.02745848, 0.014129026, 2.036028)
   validation loss 4.627913222066127e-05, (2.0657988e-05, 0.14087884, 0.052608643, 2.036028)
decoder loss ratio: 0.000112, decoder SINDy loss  ratio: 0.004332
Epoch 300
   training loss 5.680043977918103e-05, (3.722281e-05, 0.02715324, 0.011207787, 1.8456854)
   validation loss 6.789877807023004e-05, (4.6303794e-05, 0.084261395, 0.031381328, 1.8456854)
decoder loss ratio: 0.000250, decoder SINDy loss  ratio: 0.002584
Epoch 400
   training loss 0.0001290350774070248, (0.000112283364, 0.028465396, 0.008459517, 1.5905758)
   validation loss 0.0001416336017427966, (0.00012363859, 0.059072755, 0.020892639, 1.5905758)
decoder loss ratio: 0.000668, decoder SINDy loss  ratio: 0.001720
Epoch 500
   training loss 1.6346299162250943e-05, (2.305996e-06, 0.02183629, 0.0045771357, 1.358259)
   validation loss 1.8340442693443038e-05, (3.5378735e-06, 0.050057285, 0.012199797, 1.358259)
decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.001005
THRESHOLDING: 27 active coefficients
Epoch 600
   training loss 2.7755682822316885e-05, (1.4587639e-05, 0.029327111, 0.0062539107, 1.2542652)
   validation loss 3.390496567590162e-05, (1.9796133e-05, 0.06401286, 0.01566181, 1.2542652)
decoder loss ratio: 0.000107, decoder SINDy loss  ratio: 0.001290
Epoch 700
   training loss 2.4085227778414264e-05, (1.1579703e-05, 0.025352178, 0.0041700937, 1.2088515)
   validation loss 2.9513679692172445e-05, (1.6246948e-05, 0.06896914, 0.011782186, 1.2088515)
decoder loss ratio: 0.000088, decoder SINDy loss  ratio: 0.000970
Epoch 800
   training loss 1.585266727488488e-05, (3.7965842e-06, 0.028116025, 0.003554978, 1.1700585)
   validation loss 1.8518285287427716e-05, (5.806283e-06, 0.0756342, 0.010114177, 1.1700585)
decoder loss ratio: 0.000031, decoder SINDy loss  ratio: 0.000833
Epoch 900
   training loss 1.8749920855043456e-05, (6.987344e-06, 0.03321744, 0.003955745, 1.1367003)
   validation loss 2.034043427556753e-05, (8.017752e-06, 0.086217515, 0.009556785, 1.1367003)
decoder loss ratio: 0.000043, decoder SINDy loss  ratio: 0.000787
Epoch 1000
   training loss 1.6280166164506227e-05, (4.846503e-06, 0.034890145, 0.0038793527, 1.1045729)
   validation loss 1.8941209418699145e-05, (6.8066047e-06, 0.10034294, 0.010888769, 1.1045729)
decoder loss ratio: 0.000037, decoder SINDy loss  ratio: 0.000897
THRESHOLDING: 18 active coefficients
Epoch 1100
   training loss 1.5056059055496007e-05, (3.962372e-06, 0.040061977, 0.0031601898, 1.0777668)
   validation loss 1.7221516827703454e-05, (5.3334707e-06, 0.145853, 0.011103784, 1.0777668)
decoder loss ratio: 0.000029, decoder SINDy loss  ratio: 0.000914
Epoch 1200
   training loss 1.8136584913008846e-05, (7.321066e-06, 0.03833877, 0.0028326153, 1.0532258)
   validation loss 2.1247848053462803e-05, (9.7211e-06, 0.15792623, 0.009944915, 1.0532258)
decoder loss ratio: 0.000052, decoder SINDy loss  ratio: 0.000819
Epoch 1300
   training loss 1.475785938964691e-05, (4.2100173e-06, 0.036254887, 0.002487265, 1.0299116)
   validation loss 1.7887845388031565e-05, (6.655257e-06, 0.14900571, 0.009334717, 1.0299116)
decoder loss ratio: 0.000036, decoder SINDy loss  ratio: 0.000769
Epoch 1400
   training loss 1.1856384844577406e-05, (1.6806932e-06, 0.037553947, 0.0022373712, 0.9951955)
   validation loss 1.3944905731477775e-05, (3.2427379e-06, 0.12503193, 0.0075021293, 0.9951955)
decoder loss ratio: 0.000018, decoder SINDy loss  ratio: 0.000618
Epoch 1500
   training loss 1.1593364433792885e-05, (2.013686e-06, 0.035841346, 0.0019910366, 0.93805754)
   validation loss 1.3491657227859832e-05, (3.4359496e-06, 0.12741785, 0.006751323, 0.93805754)
decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.000556
THRESHOLDING: 14 active coefficients
Epoch 1600
   training loss 2.664512794581242e-05, (1.772731e-05, 0.0401188, 0.0026849068, 0.86493266)
   validation loss 3.2107778679346666e-05, (2.2566031e-05, 0.12803273, 0.008924206, 0.86493266)
decoder loss ratio: 0.000122, decoder SINDy loss  ratio: 0.000735
Epoch 1700
   training loss 1.1912870832020417e-05, (3.7627651e-06, 0.03247889, 0.0020868126, 0.7941425)
   validation loss 1.4322537936095614e-05, (5.693287e-06, 0.11838565, 0.00687826, 0.7941425)
decoder loss ratio: 0.000031, decoder SINDy loss  ratio: 0.000566
Epoch 1800
   training loss 6.075535202398896e-05, (5.2530606e-05, 0.07013779, 0.0067541054, 0.7549338)
   validation loss 5.372293162508868e-05, (4.4940396e-05, 0.1832344, 0.012331987, 0.7549338)
decoder loss ratio: 0.000243, decoder SINDy loss  ratio: 0.001015
Epoch 1900
   training loss 9.764620699570514e-06, (2.0611587e-06, 0.025452925, 0.001944876, 0.75089747)
   validation loss 1.2124617569497786e-05, (3.828385e-06, 0.12963764, 0.007872574, 0.75089747)
decoder loss ratio: 0.000021, decoder SINDy loss  ratio: 0.000648
Epoch 2000
   training loss 1.2880154827143997e-05, (5.2164323e-06, 0.025379876, 0.0018753011, 0.7476193)
   validation loss 1.5421244825120084e-05, (7.2679804e-06, 0.13133058, 0.0067707114, 0.7476193)
decoder loss ratio: 0.000039, decoder SINDy loss  ratio: 0.000558
THRESHOLDING: 7 active coefficients
Epoch 2100
   training loss 2.6466743292985484e-05, (1.8698407e-05, 0.041981112, 0.0032521356, 0.7443124)
   validation loss 3.438915518927388e-05, (2.5959887e-05, 0.16889451, 0.009861454, 0.7443124)
decoder loss ratio: 0.000140, decoder SINDy loss  ratio: 0.000812
Epoch 2200
   training loss 2.4642864445922896e-05, (1.6895614e-05, 0.043548867, 0.0033080806, 0.7416442)
   validation loss 3.0481076464639045e-05, (2.2023865e-05, 0.16910712, 0.010407686, 0.7416442)
decoder loss ratio: 0.000119, decoder SINDy loss  ratio: 0.000857
Epoch 2300
   training loss 1.3117421985953115e-05, (5.5350774e-06, 0.029791242, 0.0020075277, 0.73815924)
   validation loss 1.547164902149234e-05, (7.4335703e-06, 0.1520053, 0.006564873, 0.73815924)
decoder loss ratio: 0.000040, decoder SINDy loss  ratio: 0.000541
Epoch 2400
   training loss 1.8648723198566586e-05, (1.101752e-05, 0.036069486, 0.0027189914, 0.7359305)
   validation loss 2.4279164790641516e-05, (1.596531e-05, 0.17024381, 0.009545498, 0.7359305)
decoder loss ratio: 0.000086, decoder SINDy loss  ratio: 0.000786
Epoch 2500
   training loss 2.8758577172993682e-05, (2.1140386e-05, 0.039851654, 0.0028268686, 0.7335504)
   validation loss 2.8811267839046195e-05, (2.0759788e-05, 0.19078167, 0.0071597616, 0.7335504)
decoder loss ratio: 0.000112, decoder SINDy loss  ratio: 0.000590
THRESHOLDING: 7 active coefficients
Epoch 2600
   training loss 5.282159327180125e-05, (4.520667e-05, 0.04341645, 0.003027284, 0.7312195)
   validation loss 4.868331234320067e-05, (4.066498e-05, 0.20914476, 0.007061356, 0.7312195)
decoder loss ratio: 0.000220, decoder SINDy loss  ratio: 0.000581
Epoch 2700
   training loss 4.337073551141657e-05, (3.5776633e-05, 0.042045403, 0.0030182642, 0.72922784)
   validation loss 4.8341022193199024e-05, (4.031116e-05, 0.21097119, 0.0073758727, 0.72922784)
decoder loss ratio: 0.000218, decoder SINDy loss  ratio: 0.000607
Epoch 2800
   training loss 5.701628469978459e-05, (4.9375732e-05, 0.050142284, 0.0036710594, 0.7273448)
   validation loss 6.118293822510168e-05, (5.3144093e-05, 0.22747853, 0.00765397, 0.7273448)
decoder loss ratio: 0.000287, decoder SINDy loss  ratio: 0.000630
Epoch 2900
   training loss 1.4613778148486745e-05, (7.154168e-06, 0.038333613, 0.0021043224, 0.7249178)
   validation loss 1.846166378527414e-05, (1.05766285e-05, 0.19044049, 0.0063585793, 0.7249178)
decoder loss ratio: 0.000057, decoder SINDy loss  ratio: 0.000524
Epoch 3000
   training loss 8.959032129496336e-06, (1.5536762e-06, 0.034363333, 0.0017196706, 0.7233389)
   validation loss 1.1554378943401389e-05, (3.7151392e-06, 0.19070306, 0.0060585164, 0.7233389)
decoder loss ratio: 0.000020, decoder SINDy loss  ratio: 0.000499
THRESHOLDING: 7 active coefficients
Epoch 3100
   training loss 1.771812458173372e-05, (1.0233485e-05, 0.04423803, 0.00262448, 0.7222192)
   validation loss 2.193799809901975e-05, (1.39442445e-05, 0.2078864, 0.0077156173, 0.7222192)
decoder loss ratio: 0.000075, decoder SINDy loss  ratio: 0.000635
Epoch 3200
   training loss 1.4212968380888924e-05, (6.7741485e-06, 0.048052948, 0.0023161503, 0.72072047)
   validation loss 1.5755678759887815e-05, (7.912241e-06, 0.21851207, 0.0063623246, 0.72072047)
decoder loss ratio: 0.000043, decoder SINDy loss  ratio: 0.000524
Epoch 3300
   training loss 1.2132582924095914e-05, (4.728911e-06, 0.048930764, 0.0021089553, 0.71927774)
   validation loss 1.6624380805296823e-05, (8.7149565e-06, 0.22730063, 0.0071664816, 0.71927774)
decoder loss ratio: 0.000047, decoder SINDy loss  ratio: 0.000590
Epoch 3400
   training loss 1.642126517253928e-05, (8.9140285e-06, 0.060385834, 0.0032866881, 0.7178568)
   validation loss 2.293576835654676e-05, (1.4784622e-05, 0.26069006, 0.009725773, 0.7178568)
decoder loss ratio: 0.000080, decoder SINDy loss  ratio: 0.000801
Epoch 3500
   training loss 1.212890310853254e-05, (4.7892345e-06, 0.041266486, 0.0017178118, 0.7167887)
   validation loss 1.5588881069561467e-05, (7.720176e-06, 0.279867, 0.007008176, 0.7167887)
decoder loss ratio: 0.000042, decoder SINDy loss  ratio: 0.000577
THRESHOLDING: 7 active coefficients
Epoch 3600
   training loss 1.2836974747187924e-05, (5.473821e-06, 0.048114568, 0.0020896634, 0.71541876)
   validation loss 1.5951149180182256e-05, (8.265402e-06, 0.23466222, 0.0053155925, 0.71541876)
decoder loss ratio: 0.000045, decoder SINDy loss  ratio: 0.000438
Epoch 3700
   training loss 1.4157145415083505e-05, (6.773984e-06, 0.05324844, 0.0024669059, 0.7136472)
   validation loss 1.8076236301567405e-05, (1.0179845e-05, 0.25352466, 0.007599195, 0.7136472)
decoder loss ratio: 0.000055, decoder SINDy loss  ratio: 0.000626
Epoch 3800
   training loss 1.868546496552881e-05, (1.1323958e-05, 0.053193916, 0.00235374, 0.71261334)
   validation loss 2.295967897225637e-05, (1.4988925e-05, 0.35344362, 0.008446223, 0.71261334)
decoder loss ratio: 0.000081, decoder SINDy loss  ratio: 0.000695
Epoch 3900
   training loss 9.082361430046149e-06, (1.8266813e-06, 0.03963752, 0.0014513859, 0.7110542)
   validation loss 1.0661839041858912e-05, (3.1720012e-06, 0.2605379, 0.0037929576, 0.7110542)
decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000312
Epoch 4000
   training loss 1.165024241345236e-05, (4.358657e-06, 0.048998732, 0.0019334325, 0.70982426)
   validation loss 1.4615361578762531e-05, (6.921193e-06, 0.26345125, 0.0059592593, 0.70982426)
decoder loss ratio: 0.000037, decoder SINDy loss  ratio: 0.000491
THRESHOLDING: 7 active coefficients
Epoch 4100
   training loss 3.638610360212624e-05, (2.8899263e-05, 0.05644844, 0.0040060417, 0.7086235)
   validation loss 5.053154018241912e-05, (4.2311596e-05, 0.28415227, 0.011337069, 0.7086235)
decoder loss ratio: 0.000228, decoder SINDy loss  ratio: 0.000934
Epoch 4200
   training loss 1.1788606570917182e-05, (4.5530064e-06, 0.054771792, 0.0016093358, 0.70746666)
   validation loss 1.5023371815914288e-05, (7.3500096e-06, 0.2828901, 0.0059869573, 0.70746666)
decoder loss ratio: 0.000040, decoder SINDy loss  ratio: 0.000493
Epoch 4300
   training loss 2.1660216589225456e-05, (1.4305979e-05, 0.06959658, 0.0028947988, 0.70647585)
   validation loss 2.53828038694337e-05, (1.7475362e-05, 0.30695346, 0.00842683, 0.70647585)
decoder loss ratio: 0.000094, decoder SINDy loss  ratio: 0.000694
Epoch 4400
   training loss 1.4086474038776942e-05, (6.8611066e-06, 0.05363436, 0.0017036321, 0.7055004)
   validation loss 1.642253846512176e-05, (8.6939735e-06, 0.28855443, 0.0067356024, 0.7055004)
decoder loss ratio: 0.000047, decoder SINDy loss  ratio: 0.000555
Epoch 4500
   training loss 1.5165920558501966e-05, (7.953181e-06, 0.05428047, 0.0016569165, 0.7047048)
   validation loss 1.885468554974068e-05, (1.1400843e-05, 0.29105124, 0.004067942, 0.7047048)
decoder loss ratio: 0.000062, decoder SINDy loss  ratio: 0.000335
THRESHOLDING: 7 active coefficients
Epoch 4600
   training loss 1.665149102336727e-05, (9.420792e-06, 0.067076996, 0.0019255087, 0.7038148)
   validation loss 1.7935306459548883e-05, (1.0445026e-05, 0.30965415, 0.0045213294, 0.7038148)
decoder loss ratio: 0.000056, decoder SINDy loss  ratio: 0.000372
Epoch 4700
   training loss 1.6062384020187892e-05, (8.842393e-06, 0.06665245, 0.0019110604, 0.70288855)
   validation loss 1.8831133274943568e-05, (1.1249005e-05, 0.33415845, 0.0055324305, 0.70288855)
decoder loss ratio: 0.000061, decoder SINDy loss  ratio: 0.000456
Epoch 4800
   training loss 1.11844674393069e-05, (3.995401e-06, 0.06374877, 0.0016860813, 0.70204586)
   validation loss 1.3836802281730343e-05, (6.4243295e-06, 0.3018502, 0.003920145, 0.70204586)
decoder loss ratio: 0.000035, decoder SINDy loss  ratio: 0.000323
Epoch 4900
   training loss 1.1817936865554657e-05, (4.621787e-06, 0.06505477, 0.0018268636, 0.70134634)
   validation loss 1.3676903108716942e-05, (6.193903e-06, 0.3091397, 0.0046953647, 0.70134634)
decoder loss ratio: 0.000033, decoder SINDy loss  ratio: 0.000387
Epoch 5000
   training loss 1.404381328029558e-05, (6.8457084e-06, 0.07173008, 0.0019373298, 0.70043725)
   validation loss 1.7475802451372147e-05, (1.006584e-05, 0.33517605, 0.0040558963, 0.70043725)
decoder loss ratio: 0.000054, decoder SINDy loss  ratio: 0.000334
THRESHOLDING: 7 active coefficients
REFINEMENT
Epoch 0
   training loss 1.2044839650116046e-06, (1.0720681e-06, 0.06566143, 0.0013241586, 0.7034863)
   validation loss 1.994047579501057e-06, (1.691081e-06, 0.29017204, 0.0030296668, 0.7034863)
decoder loss ratio: 0.000009, decoder SINDy loss  ratio: 0.000249
Epoch 100
   training loss 3.3956764582399046e-06, (3.2695245e-06, 0.05069797, 0.00126152, 0.71802324)
   validation loss 5.5881023399706464e-06, (5.156567e-06, 0.27640176, 0.004315352, 0.71802324)
decoder loss ratio: 0.000028, decoder SINDy loss  ratio: 0.000355
Epoch 200
   training loss 3.22227310789458e-06, (3.1069726e-06, 0.048402015, 0.0011530058, 0.72051185)
   validation loss 4.480498319026083e-06, (4.1394374e-06, 0.22975062, 0.003410612, 0.72051185)
decoder loss ratio: 0.000022, decoder SINDy loss  ratio: 0.000281
Epoch 300
   training loss 1.688846623437712e-06, (1.5550712e-06, 0.0480489, 0.0013377537, 0.7221698)
   validation loss 3.1045124160300475e-06, (2.7940873e-06, 0.26845634, 0.003104252, 0.7221698)
decoder loss ratio: 0.000015, decoder SINDy loss  ratio: 0.000256
Epoch 400
   training loss 3.284231070210808e-06, (3.1083705e-06, 0.055325102, 0.0017586057, 0.7231303)
   validation loss 4.758221621159464e-06, (4.371025e-06, 0.27498797, 0.0038719669, 0.7231303)
decoder loss ratio: 0.000024, decoder SINDy loss  ratio: 0.000319
Epoch 500
   training loss 3.2733748867030954e-06, (3.1492173e-06, 0.05513726, 0.0012415771, 0.7246412)
   validation loss 4.796105713467114e-06, (4.4618637e-06, 0.31213504, 0.0033424182, 0.7246412)
decoder loss ratio: 0.000024, decoder SINDy loss  ratio: 0.000275
Epoch 600
   training loss 1.3281047586133354e-06, (1.1991015e-06, 0.052879486, 0.0012900335, 0.72534734)
   validation loss 2.381098056503106e-06, (2.1107853e-06, 0.2830437, 0.0027031265, 0.72534734)
decoder loss ratio: 0.000011, decoder SINDy loss  ratio: 0.000223
Epoch 700
   training loss 2.3152755602495745e-05, (2.2802727e-05, 0.07493905, 0.0035002779, 0.7266012)
   validation loss 3.615940295276232e-05, (3.5019653e-05, 0.44629747, 0.011397481, 0.7266012)
decoder loss ratio: 0.000189, decoder SINDy loss  ratio: 0.000938
Epoch 800
   training loss 3.3733417694747914e-06, (3.2390371e-06, 0.060709912, 0.0013430471, 0.72751904)
   validation loss 4.837535016122274e-06, (4.4352787e-06, 0.30775252, 0.0040225647, 0.72751904)
decoder loss ratio: 0.000024, decoder SINDy loss  ratio: 0.000331
Epoch 900
   training loss 4.086886292498093e-06, (3.990057e-06, 0.046809673, 0.0009682926, 0.72833616)
   validation loss 5.502597105078166e-06, (5.2048013e-06, 0.29183275, 0.0029779568, 0.72833616)
decoder loss ratio: 0.000028, decoder SINDy loss  ratio: 0.000245
Epoch 1000
   training loss 4.7191524572554044e-06, (4.567093e-06, 0.06323337, 0.0015205956, 0.72861457)
   validation loss 6.813762865931494e-06, (6.499726e-06, 0.258234, 0.0031403652, 0.72861457)
decoder loss ratio: 0.000035, decoder SINDy loss  ratio: 0.000259
EXPERIMENT 1
TRAINING
Epoch 0
   training loss 0.024892183020710945, (0.024187978, 803.293, 6.973271, 0.68760884)
   validation loss 0.039267875254154205, (0.037742317, 885.70953, 15.186815, 0.68760884)
decoder loss ratio: 0.203802, decoder SINDy loss  ratio: 1.250518
Epoch 100
   training loss 5.749379488406703e-05, (2.7483986e-05, 0.2927568, 0.15659408, 1.4350399)
   validation loss 0.00014087517047300935, (5.122966e-05, 1.1300875, 0.752951, 1.4350399)
decoder loss ratio: 0.000277, decoder SINDy loss  ratio: 0.062000
Epoch 200
   training loss 5.323515506461263e-05, (2.970853e-05, 0.09494058, 0.06334914, 1.7191715)
   validation loss 8.802406227914616e-05, (4.2390824e-05, 0.45101804, 0.28441525, 1.7191715)
decoder loss ratio: 0.000229, decoder SINDy loss  ratio: 0.023419
Epoch 300
   training loss 2.5759940399439074e-05, (3.751082e-06, 0.062461257, 0.039524525, 1.8056406)
   validation loss 4.093216193723492e-05, (9.259673e-06, 0.29284266, 0.13616085, 1.8056406)
decoder loss ratio: 0.000050, decoder SINDy loss  ratio: 0.011212
Epoch 400
   training loss 3.59590703737922e-05, (1.4723926e-05, 0.05555408, 0.03291797, 1.7943347)
   validation loss 5.2096664148848504e-05, (2.4791914e-05, 0.22282574, 0.093614034, 1.7943347)
decoder loss ratio: 0.000134, decoder SINDy loss  ratio: 0.007708
Epoch 500
   training loss 5.117039108881727e-05, (3.1184863e-05, 0.053019434, 0.027199257, 1.7265601)
   validation loss 6.828369077993557e-05, (4.3392152e-05, 0.17933138, 0.07625939, 1.7265601)
decoder loss ratio: 0.000234, decoder SINDy loss  ratio: 0.006279
THRESHOLDING: 41 active coefficients
Epoch 600
   training loss 2.9241044103400782e-05, (1.0543909e-05, 0.051460195, 0.024385678, 1.6258569)
   validation loss 4.009564872831106e-05, (1.6964728e-05, 0.15482506, 0.068723544, 1.6258569)
decoder loss ratio: 0.000092, decoder SINDy loss  ratio: 0.005659
Epoch 700
   training loss 2.0299832613090985e-05, (2.5913287e-06, 0.05417267, 0.024173003, 1.5291203)
   validation loss 2.6801530111697502e-05, (5.2135765e-06, 0.15236649, 0.06296751, 1.5291203)
decoder loss ratio: 0.000028, decoder SINDy loss  ratio: 0.005185
Epoch 800
   training loss 2.5957935577025637e-05, (9.099157e-06, 0.053803224, 0.023056742, 1.4553105)
   validation loss 3.411170473555103e-05, (1.3828301e-05, 0.14081249, 0.057303004, 1.4553105)
decoder loss ratio: 0.000075, decoder SINDy loss  ratio: 0.004718
Epoch 900
   training loss 2.5303444999735802e-05, (9.245758e-06, 0.051724132, 0.020705272, 1.3987161)
   validation loss 3.40063197654672e-05, (1.4990491e-05, 0.133901, 0.050286673, 1.3987161)
decoder loss ratio: 0.000081, decoder SINDy loss  ratio: 0.004141
Epoch 1000
   training loss 1.6522157238796353e-05, (1.0002467e-06, 0.053017825, 0.020846166, 1.3437294)
   validation loss 2.1322952306945808e-05, (3.177378e-06, 0.13111144, 0.04708282, 1.3437294)
decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.003877
THRESHOLDING: 30 active coefficients
Epoch 1100
   training loss 2.402841164439451e-05, (9.058747e-06, 0.059402954, 0.021096114, 1.2860054)
   validation loss 3.385788295418024e-05, (1.6340608e-05, 0.14461166, 0.04657222, 1.2860054)
decoder loss ratio: 0.000088, decoder SINDy loss  ratio: 0.003835
Epoch 1200
   training loss 4.431036359164864e-05, (2.9098643e-05, 0.07193831, 0.027990729, 1.2412649)
   validation loss 5.664055788656697e-05, (3.8192575e-05, 0.15382993, 0.06035334, 1.2412649)
decoder loss ratio: 0.000206, decoder SINDy loss  ratio: 0.004970
Epoch 1300
   training loss 5.814000905957073e-05, (4.388211e-05, 0.07230316, 0.022624848, 1.1995412)
   validation loss 7.338864816119894e-05, (5.6136294e-05, 0.1597647, 0.052569445, 1.1995412)
decoder loss ratio: 0.000303, decoder SINDy loss  ratio: 0.004329
Epoch 1400
   training loss 3.637519694166258e-05, (2.2654624e-05, 0.074075185, 0.021744298, 1.1546146)
   validation loss 4.356217323220335e-05, (2.7144135e-05, 0.16052571, 0.048718955, 1.1546146)
decoder loss ratio: 0.000147, decoder SINDy loss  ratio: 0.004012
Epoch 1500
   training loss 3.629621278378181e-05, (2.2069238e-05, 0.09985659, 0.031085549, 1.1118419)
   validation loss 4.981471647624858e-05, (3.2384178e-05, 0.19325712, 0.06312119, 1.1118419)
decoder loss ratio: 0.000175, decoder SINDy loss  ratio: 0.005198
THRESHOLDING: 24 active coefficients
Epoch 1600
   training loss 1.63419172167778e-05, (3.2105659e-06, 0.08593142, 0.023550795, 1.0776272)
   validation loss 2.0599640265572816e-05, (5.311812e-06, 0.17547283, 0.04511557, 1.0776272)
decoder loss ratio: 0.000029, decoder SINDy loss  ratio: 0.003715
Epoch 1700
   training loss 1.4748487956239842e-05, (2.100917e-06, 0.08447268, 0.021436315, 1.0503939)
   validation loss 1.806373256840743e-05, (3.7201355e-06, 0.17214398, 0.038396586, 1.0503939)
decoder loss ratio: 0.000020, decoder SINDy loss  ratio: 0.003162
Epoch 1800
   training loss 1.553492620587349e-05, (3.2130704e-06, 0.08909571, 0.020820405, 1.0239816)
   validation loss 1.892938234959729e-05, (4.9422783e-06, 0.17341161, 0.037472896, 1.0239816)
decoder loss ratio: 0.000027, decoder SINDy loss  ratio: 0.003086
Epoch 1900
   training loss 5.91949574300088e-05, (4.646215e-05, 0.097310245, 0.027491875, 0.99836165)
   validation loss 7.818260928615928e-05, (6.3263855e-05, 0.18716702, 0.049351387, 0.99836165)
decoder loss ratio: 0.000342, decoder SINDy loss  ratio: 0.004064
Epoch 2000
   training loss 1.5246066141116899e-05, (3.2192834e-06, 0.10602432, 0.022659857, 0.97607976)
   validation loss 2.004111411224585e-05, (6.035141e-06, 0.18903929, 0.04245176, 0.97607976)
decoder loss ratio: 0.000033, decoder SINDy loss  ratio: 0.003496
THRESHOLDING: 23 active coefficients
Epoch 2100
   training loss 2.0285715436330065e-05, (8.513349e-06, 0.111846305, 0.02242985, 0.9529382)
   validation loss 2.642927756824065e-05, (1.26478135e-05, 0.19718325, 0.042520817, 0.9529382)
decoder loss ratio: 0.000068, decoder SINDy loss  ratio: 0.003501
Epoch 2200
   training loss 1.9425871869316325e-05, (8.073372e-06, 0.112975605, 0.020682696, 0.92842305)
   validation loss 2.553247395553626e-05, (1.2529571e-05, 0.19674961, 0.037186727, 0.92842305)
decoder loss ratio: 0.000068, decoder SINDy loss  ratio: 0.003062
Epoch 2300
   training loss 1.4367512449098285e-05, (3.3950296e-06, 0.11125412, 0.019287407, 0.9043743)
   validation loss 1.9927403627661988e-05, (7.352226e-06, 0.19733581, 0.035314344, 0.9043743)
decoder loss ratio: 0.000040, decoder SINDy loss  ratio: 0.002908
Epoch 2400
   training loss 1.8763792468234897e-05, (7.906081e-06, 0.12604086, 0.020450525, 0.8812659)
   validation loss 2.521897476981394e-05, (1.2692494e-05, 0.21855, 0.03713821, 0.8812659)
decoder loss ratio: 0.000069, decoder SINDy loss  ratio: 0.003058
Epoch 2500
   training loss 1.4303204807220027e-05, (3.7025088e-06, 0.1254573, 0.020034786, 0.85972184)
   validation loss 2.0126000890741125e-05, (7.68787e-06, 0.22021195, 0.03840915, 0.85972184)
decoder loss ratio: 0.000042, decoder SINDy loss  ratio: 0.003163
THRESHOLDING: 19 active coefficients
Epoch 2600
   training loss 1.4225609447748866e-05, (4.0023874e-06, 0.13730384, 0.0196523, 0.8257992)
   validation loss 1.7822751033236273e-05, (6.12286e-06, 0.23980914, 0.034418996, 0.8257992)
decoder loss ratio: 0.000033, decoder SINDy loss  ratio: 0.002834
Epoch 2700
   training loss 1.1333351721987128e-05, (1.1612191e-06, 0.13801037, 0.020451503, 0.8126983)
   validation loss 1.6052530554588884e-05, (4.1881285e-06, 0.24460706, 0.037374195, 0.8126983)
decoder loss ratio: 0.000023, decoder SINDy loss  ratio: 0.003077
Epoch 2800
   training loss 1.4479970559477806e-05, (4.263205e-06, 0.14156769, 0.022046966, 0.8012069)
   validation loss 2.057055098703131e-05, (8.510452e-06, 0.25902942, 0.040480293, 0.8012069)
decoder loss ratio: 0.000046, decoder SINDy loss  ratio: 0.003333
Epoch 2900
   training loss 1.6320900613209233e-05, (6.367696e-06, 0.15352793, 0.020533241, 0.78998816)
   validation loss 2.321487045264803e-05, (1.1138616e-05, 0.26676, 0.04176374, 0.78998816)
decoder loss ratio: 0.000060, decoder SINDy loss  ratio: 0.003439
Epoch 3000
   training loss 1.7630422007641755e-05, (7.8549e-06, 0.1543476, 0.019828655, 0.77926564)
   validation loss 2.4910181309678592e-05, (1.3650014e-05, 0.26588565, 0.034675114, 0.77926564)
decoder loss ratio: 0.000074, decoder SINDy loss  ratio: 0.002855
THRESHOLDING: 18 active coefficients
Epoch 3100
   training loss 1.987587529583834e-05, (1.0141312e-05, 0.16541657, 0.020215841, 0.771298)
   validation loss 2.6567624445306137e-05, (1.4812494e-05, 0.27840084, 0.040421512, 0.771298)
decoder loss ratio: 0.000080, decoder SINDy loss  ratio: 0.003328
Epoch 3200
   training loss 1.3561753803514875e-05, (3.830666e-06, 0.15959834, 0.021180935, 0.7612995)
   validation loss 1.9196279026800767e-05, (7.671582e-06, 0.27368823, 0.039117027, 0.7612995)
decoder loss ratio: 0.000041, decoder SINDy loss  ratio: 0.003221
Epoch 3300
   training loss 1.4205239494913258e-05, (4.706282e-06, 0.16712682, 0.019854885, 0.7513469)
   validation loss 1.97447334358003e-05, (8.726882e-06, 0.28528613, 0.035043843, 0.7513469)
decoder loss ratio: 0.000047, decoder SINDy loss  ratio: 0.002886
Epoch 3400
   training loss 1.1918226846319158e-05, (2.6030307e-06, 0.16827922, 0.018922117, 0.7422985)
   validation loss 1.6387804862461053e-05, (5.5745954e-06, 0.29284695, 0.033902243, 0.7422985)
decoder loss ratio: 0.000030, decoder SINDy loss  ratio: 0.002792
Epoch 3500
   training loss 1.952962702489458e-05, (1.0115291e-05, 0.18296105, 0.020765152, 0.73378223)
   validation loss 2.825690171448514e-05, (1.667212e-05, 0.3118858, 0.04246959, 0.73378223)
decoder loss ratio: 0.000090, decoder SINDy loss  ratio: 0.003497
THRESHOLDING: 18 active coefficients
Epoch 3600
   training loss 2.3507673176936805e-05, (1.4115486e-05, 0.18501753, 0.021446556, 0.7247532)
   validation loss 3.41954619216267e-05, (2.2433987e-05, 0.32735437, 0.045139443, 0.7247532)
decoder loss ratio: 0.000121, decoder SINDy loss  ratio: 0.003717
Epoch 3700
   training loss 1.6459989637951367e-05, (7.2134894e-06, 0.1888537, 0.020864187, 0.7160082)
   validation loss 2.306693568243645e-05, (1.1967507e-05, 0.3278738, 0.03939348, 0.7160082)
decoder loss ratio: 0.000065, decoder SINDy loss  ratio: 0.003244
Epoch 3800
   training loss 1.4380932043422945e-05, (5.3053627e-06, 0.18735933, 0.019949524, 0.70806175)
   validation loss 1.890697967610322e-05, (8.5813745e-06, 0.323339, 0.032449882, 0.70806175)
decoder loss ratio: 0.000046, decoder SINDy loss  ratio: 0.002672
Epoch 3900
   training loss 1.8105436538462527e-05, (9.002182e-06, 0.19755237, 0.020997258, 0.70035285)
   validation loss 2.5081819330807775e-05, (1.4231096e-05, 0.36166763, 0.038471956, 0.70035285)
decoder loss ratio: 0.000077, decoder SINDy loss  ratio: 0.003168
Epoch 4000
   training loss 1.8897681002272293e-05, (9.9000345e-06, 0.2017371, 0.020694729, 0.6928174)
   validation loss 2.71715998678701e-05, (1.6340953e-05, 0.37463418, 0.039024733, 0.6928174)
decoder loss ratio: 0.000088, decoder SINDy loss  ratio: 0.003213
THRESHOLDING: 17 active coefficients
Epoch 4100
   training loss 1.2883054296253249e-05, (4.015762e-06, 0.20680426, 0.021432001, 0.67240924)
   validation loss 1.8379219909547828e-05, (7.799848e-06, 0.37508646, 0.038552795, 0.67240924)
decoder loss ratio: 0.000042, decoder SINDy loss  ratio: 0.003175
Epoch 4200
   training loss 1.0821180694620125e-05, (2.1210212e-06, 0.20359755, 0.020294435, 0.66707164)
   validation loss 1.364758463751059e-05, (3.847803e-06, 0.38141787, 0.03129066, 0.66707164)
decoder loss ratio: 0.000021, decoder SINDy loss  ratio: 0.002577
Epoch 4300
   training loss 1.5227734365907963e-05, (6.334052e-06, 0.21639366, 0.022686433, 0.6625039)
   validation loss 2.3369859263766557e-05, (1.2392384e-05, 0.39179322, 0.04352437, 0.6625039)
decoder loss ratio: 0.000067, decoder SINDy loss  ratio: 0.003584
Epoch 4400
   training loss 1.4747874956810847e-05, (6.0896264e-06, 0.2124122, 0.020790959, 0.65791523)
   validation loss 2.0543333448586054e-05, (1.0325072e-05, 0.43078053, 0.03639109, 0.65791523)
decoder loss ratio: 0.000056, decoder SINDy loss  ratio: 0.002997
Epoch 4500
   training loss 2.0876865164609626e-05, (1.234095e-05, 0.21783312, 0.01993711, 0.6542206)
   validation loss 2.793360545183532e-05, (1.7930528e-05, 0.4100292, 0.034608703, 0.6542206)
decoder loss ratio: 0.000097, decoder SINDy loss  ratio: 0.002850
THRESHOLDING: 17 active coefficients
Epoch 4600
   training loss 9.839418453339022e-06, (1.4016998e-06, 0.21792078, 0.019372955, 0.65004236)
   validation loss 1.2777095435012598e-05, (3.2136652e-06, 0.42275232, 0.030630069, 0.65004236)
decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.002522
Epoch 4700
   training loss 2.9284925403771922e-05, (2.0540283e-05, 0.23441653, 0.022869308, 0.6457711)
   validation loss 4.5826771383872256e-05, (3.4243305e-05, 0.47263056, 0.051257554, 0.6457711)
decoder loss ratio: 0.000185, decoder SINDy loss  ratio: 0.004221
Epoch 4800
   training loss 1.3603023944597226e-05, (5.0493836e-06, 0.23470724, 0.021334875, 0.64201534)
   validation loss 2.0635645341826603e-05, (1.017479e-05, 0.44544983, 0.04040702, 0.64201534)
decoder loss ratio: 0.000055, decoder SINDy loss  ratio: 0.003327
Epoch 4900
   training loss 1.1791347787948325e-05, (3.3881051e-06, 0.23466678, 0.020167923, 0.63864505)
   validation loss 1.5747060388093814e-05, (5.756535e-06, 0.45538592, 0.03604075, 0.63864505)
decoder loss ratio: 0.000031, decoder SINDy loss  ratio: 0.002968
Epoch 5000
   training loss 1.5168744539550971e-05, (6.7557194e-06, 0.2359014, 0.02062663, 0.63503623)
   validation loss 2.108164335368201e-05, (1.1128469e-05, 0.4817038, 0.03602812, 0.63503623)
decoder loss ratio: 0.000060, decoder SINDy loss  ratio: 0.002967
THRESHOLDING: 17 active coefficients
REFINEMENT
Epoch 0
   training loss 3.475982794043375e-06, (1.5714907e-06, 0.22869794, 0.01904492, 0.63713425)
   validation loss 5.946614692220464e-06, (3.0451151e-06, 0.44133756, 0.029014999, 0.63713425)
decoder loss ratio: 0.000016, decoder SINDy loss  ratio: 0.002389
Epoch 100
   training loss 9.913906069414224e-06, (8.303635e-06, 0.16631302, 0.01610271, 0.70395565)
   validation loss 1.4339944755192846e-05, (1.1814468e-05, 0.33559608, 0.025254764, 0.70395565)
decoder loss ratio: 0.000064, decoder SINDy loss  ratio: 0.002080
Epoch 200
   training loss 3.631579829743714e-06, (2.282568e-06, 0.14598636, 0.013490119, 0.7357844)
   validation loss 6.983565072005149e-06, (4.569943e-06, 0.31330365, 0.02413622, 0.7357844)
decoder loss ratio: 0.000025, decoder SINDy loss  ratio: 0.001987
Epoch 300
   training loss 6.219902388693299e-06, (4.86465e-06, 0.13045768, 0.013552525, 0.76075816)
   validation loss 8.724019608052913e-06, (6.570442e-06, 0.26928583, 0.021535777, 0.76075816)
decoder loss ratio: 0.000035, decoder SINDy loss  ratio: 0.001773
Epoch 400
   training loss 3.0620240067946725e-06, (1.8850093e-06, 0.11710898, 0.011770148, 0.78069377)
   validation loss 5.081163180875592e-06, (3.1688064e-06, 0.2377983, 0.019123565, 0.78069377)
decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.001575
Epoch 500
   training loss 3.0611515740019968e-06, (1.9037665e-06, 0.10931298, 0.011573851, 0.79768693)
   validation loss 5.1720817282330245e-06, (3.2374733e-06, 0.21841471, 0.019346086, 0.79768693)
decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.001593
Epoch 600
   training loss 7.63906973588746e-06, (6.4117085e-06, 0.10801405, 0.012273613, 0.81294703)
   validation loss 1.263240756088635e-05, (1.0303727e-05, 0.2032027, 0.023286805, 0.81294703)
decoder loss ratio: 0.000056, decoder SINDy loss  ratio: 0.001917
Epoch 700
   training loss 5.858792064827867e-06, (4.5962315e-06, 0.10739148, 0.012625608, 0.824929)
   validation loss 9.681210940470919e-06, (7.2416387e-06, 0.1941165, 0.024395725, 0.824929)
decoder loss ratio: 0.000039, decoder SINDy loss  ratio: 0.002009
Epoch 800
   training loss 1.4511607332678977e-05, (1.3176199e-05, 0.10667791, 0.013354084, 0.83457124)
   validation loss 2.4223085347330198e-05, (2.0794163e-05, 0.19623865, 0.034289233, 0.83457124)
decoder loss ratio: 0.000112, decoder SINDy loss  ratio: 0.002823
Epoch 900
   training loss 4.385876309243031e-06, (3.3401427e-06, 0.09636364, 0.010457335, 0.8446243)
   validation loss 7.527543402829906e-06, (5.665708e-06, 0.16670221, 0.018618353, 0.8446243)
decoder loss ratio: 0.000031, decoder SINDy loss  ratio: 0.001533
Epoch 1000
   training loss 3.912922693416476e-05, (3.7579324e-05, 0.11288104, 0.015499024, 0.8545241)
   validation loss 5.272864655125886e-05, (4.838591e-05, 0.20047697, 0.043427363, 0.8545241)
decoder loss ratio: 0.000261, decoder SINDy loss  ratio: 0.003576
EXPERIMENT 2
TRAINING
Epoch 0
   training loss 0.025255797430872917, (0.024301833, 1501.6241, 9.467438, 0.72208345)
   validation loss 0.03956953063607216, (0.037876457, 1649.719, 16.858526, 0.72208345)
decoder loss ratio: 0.204527, decoder SINDy loss  ratio: 1.388171
Epoch 100
   training loss 4.180461837677285e-05, (1.7239494e-05, 0.082117915, 0.049780842, 1.9587038)
   validation loss 6.0600523283937946e-05, (2.8568966e-05, 0.26933274, 0.12444519, 1.9587038)
decoder loss ratio: 0.000154, decoder SINDy loss  ratio: 0.010247
Epoch 200
   training loss 0.00016566396516282111, (0.00014459193, 0.037029278, 0.02569986, 1.8502045)
   validation loss 0.00022293413348961622, (0.00019887526, 0.08707764, 0.055568248, 1.8502045)
decoder loss ratio: 0.001074, decoder SINDy loss  ratio: 0.004576
Epoch 300
   training loss 2.8616092095035128e-05, (1.2327643e-05, 0.019662548, 0.007881381, 1.5500312)
   validation loss 3.552556154318154e-05, (1.8349087e-05, 0.04957486, 0.016761666, 1.5500312)
decoder loss ratio: 0.000099, decoder SINDy loss  ratio: 0.001380
Epoch 400
   training loss 2.4152988771675155e-05, (9.981794e-06, 0.018381016, 0.005418867, 1.3629307)
   validation loss 2.937891986221075e-05, (1.4589788e-05, 0.045730688, 0.011598254, 1.3629307)
decoder loss ratio: 0.000079, decoder SINDy loss  ratio: 0.000955
Epoch 500
   training loss 1.5077764146553818e-05, (2.765095e-06, 0.015632173, 0.003952535, 1.1917416)
   validation loss 1.7681792087387294e-05, (4.7836056e-06, 0.04362593, 0.009807713, 1.1917416)
decoder loss ratio: 0.000026, decoder SINDy loss  ratio: 0.000808
THRESHOLDING: 22 active coefficients
Epoch 600
   training loss 1.8474664102541283e-05, (7.70933e-06, 0.022539273, 0.0053741247, 1.0227923)
   validation loss 2.4565695639466867e-05, (1.2941526e-05, 0.06680361, 0.013962465, 1.0227923)
decoder loss ratio: 0.000070, decoder SINDy loss  ratio: 0.001150
Epoch 700
   training loss 2.019306703004986e-05, (1.0731134e-05, 0.022293942, 0.0040765475, 0.9054279)
   validation loss 2.4824596039252356e-05, (1.460262e-05, 0.071268536, 0.011676992, 0.9054279)
decoder loss ratio: 0.000079, decoder SINDy loss  ratio: 0.000962
Epoch 800
   training loss 2.826941999956034e-05, (1.9504001e-05, 0.022711879, 0.0034235192, 0.8423068)
   validation loss 3.5772405681200325e-05, (2.6195941e-05, 0.0818665, 0.011533965, 0.8423068)
decoder loss ratio: 0.000141, decoder SINDy loss  ratio: 0.000950
Epoch 900
   training loss 4.575264756567776e-05, (3.7111997e-05, 0.030825315, 0.0038494891, 0.82557005)
   validation loss 5.874811176909134e-05, (4.9266488e-05, 0.101254426, 0.012259237, 0.82557005)
decoder loss ratio: 0.000266, decoder SINDy loss  ratio: 0.001009
Epoch 1000
   training loss 1.0797699360409752e-05, (2.4505105e-06, 0.021839788, 0.0023780284, 0.8109386)
   validation loss 1.238020104210591e-05, (3.6477222e-06, 0.087021194, 0.0062309294, 0.8109386)
decoder loss ratio: 0.000020, decoder SINDy loss  ratio: 0.000513
THRESHOLDING: 7 active coefficients
Epoch 1100
   training loss 2.05024207389215e-05, (1.2012173e-05, 0.02651676, 0.0034761108, 0.8142637)
   validation loss 2.9113638447597623e-05, (1.9637926e-05, 0.08227687, 0.013330761, 0.8142637)
decoder loss ratio: 0.000106, decoder SINDy loss  ratio: 0.001098
Epoch 1200
   training loss 2.5208722945535555e-05, (1.6760376e-05, 0.032301508, 0.004043428, 0.8044004)
   validation loss 3.220724465791136e-05, (2.300748e-05, 0.08825016, 0.011557581, 0.8044004)
decoder loss ratio: 0.000124, decoder SINDy loss  ratio: 0.000952
Epoch 1300
   training loss 1.29056516016135e-05, (4.788013e-06, 0.018371457, 0.0017168017, 0.79459584)
   validation loss 1.487952522438718e-05, (6.340568e-06, 0.07546525, 0.005929998, 0.79459584)
decoder loss ratio: 0.000034, decoder SINDy loss  ratio: 0.000488
Epoch 1400
   training loss 1.3628622582473326e-05, (5.606099e-06, 0.018631892, 0.001561784, 0.7866345)
   validation loss 1.5540510503342375e-05, (7.143312e-06, 0.07728473, 0.0053085415, 0.7866345)
decoder loss ratio: 0.000039, decoder SINDy loss  ratio: 0.000437
Epoch 1500
   training loss 1.5132063708733767e-05, (7.2060193e-06, 0.020017626, 0.0012957627, 0.77964675)
   validation loss 1.8222724975203164e-05, (9.889416e-06, 0.08351603, 0.0053684097, 0.77964675)
decoder loss ratio: 0.000053, decoder SINDy loss  ratio: 0.000442
THRESHOLDING: 7 active coefficients
Epoch 1600
   training loss 1.115608392865397e-05, (3.2849725e-06, 0.020030132, 0.0013424156, 0.773687)
   validation loss 1.3160380149201956e-05, (4.938376e-06, 0.089048535, 0.0048513445, 0.773687)
decoder loss ratio: 0.000027, decoder SINDy loss  ratio: 0.000399
Epoch 1700
   training loss 1.3521967048291117e-05, (5.615432e-06, 0.029144974, 0.0021860858, 0.7687927)
   validation loss 1.5564073692075908e-05, (7.2366006e-06, 0.108326316, 0.0063954643, 0.7687927)
decoder loss ratio: 0.000039, decoder SINDy loss  ratio: 0.000527
Epoch 1800
   training loss 1.256801715499023e-05, (4.7409426e-06, 0.027999612, 0.001825761, 0.7644499)
   validation loss 1.5786150470376015e-05, (7.4099503e-06, 0.12513381, 0.007317027, 0.7644499)
decoder loss ratio: 0.000040, decoder SINDy loss  ratio: 0.000603
Epoch 1900
   training loss 1.628792415431235e-05, (8.448272e-06, 0.030490806, 0.0023820838, 0.7601445)
   validation loss 2.119486998708453e-05, (1.2852909e-05, 0.13447142, 0.00740517, 0.7601445)
decoder loss ratio: 0.000069, decoder SINDy loss  ratio: 0.000610
Epoch 2000
   training loss 1.046397301252e-05, (2.730623e-06, 0.025543176, 0.0016983807, 0.7563512)
   validation loss 1.2854432497988455e-05, (4.580807e-06, 0.12335759, 0.007101145, 0.7563512)
decoder loss ratio: 0.000025, decoder SINDy loss  ratio: 0.000585
THRESHOLDING: 7 active coefficients
Epoch 2100
   training loss 1.3808369658363517e-05, (6.15081e-06, 0.02795913, 0.0012668653, 0.75308734)
   validation loss 1.5192155842669308e-05, (7.1637487e-06, 0.12322739, 0.0049753487, 0.75308734)
decoder loss ratio: 0.000039, decoder SINDy loss  ratio: 0.000410
Epoch 2200
   training loss 1.2278098438400775e-05, (4.6367527e-06, 0.029232102, 0.001445621, 0.74967843)
   validation loss 1.4336705135065131e-05, (6.3634247e-06, 0.11863959, 0.004764967, 0.74967843)
decoder loss ratio: 0.000034, decoder SINDy loss  ratio: 0.000392
Epoch 2300
   training loss 9.684585165814497e-06, (2.0790671e-06, 0.03157526, 0.0014222835, 0.74632895)
   validation loss 1.0953610399155878e-05, (3.07452e-06, 0.11987046, 0.0041580084, 0.74632895)
decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000342
Epoch 2400
   training loss 1.2027729098917916e-05, (4.455368e-06, 0.04119192, 0.0013905768, 0.7433304)
   validation loss 1.4065824871067889e-05, (6.1861856e-06, 0.114213854, 0.0044633504, 0.7433304)
decoder loss ratio: 0.000033, decoder SINDy loss  ratio: 0.000368
Epoch 2500
   training loss 1.1680351235554554e-05, (4.1261555e-06, 0.036973912, 0.0014397093, 0.7410225)
   validation loss 1.4700697647640482e-05, (6.8015793e-06, 0.11458853, 0.004888938, 0.7410225)
decoder loss ratio: 0.000037, decoder SINDy loss  ratio: 0.000403
THRESHOLDING: 6 active coefficients
Epoch 2600
   training loss 1.1033179362129886e-05, (3.5169837e-06, 0.043432653, 0.0012980422, 0.7386392)
   validation loss 1.2173543836979661e-05, (4.431131e-06, 0.12140936, 0.0035602145, 0.7386392)
decoder loss ratio: 0.000024, decoder SINDy loss  ratio: 0.000293
Epoch 2700
   training loss 1.5326633729273453e-05, (7.739269e-06, 0.057590067, 0.0023067943, 0.73566854)
   validation loss 1.825721119530499e-05, (1.0201502e-05, 0.15400274, 0.006990242, 0.73566854)
decoder loss ratio: 0.000055, decoder SINDy loss  ratio: 0.000576
Epoch 2800
   training loss 1.4124346307653468e-05, (6.6404687e-06, 0.048846036, 0.0015351622, 0.73303616)
   validation loss 1.762709507602267e-05, (9.8540895e-06, 0.14673287, 0.004426448, 0.73303616)
decoder loss ratio: 0.000053, decoder SINDy loss  ratio: 0.000364
Epoch 2900
   training loss 2.8704402211587876e-05, (2.1107826e-05, 0.06418929, 0.0029270612, 0.7303871)
   validation loss 3.918830770999193e-05, (3.074337e-05, 0.19484596, 0.011410663, 0.7303871)
decoder loss ratio: 0.000166, decoder SINDy loss  ratio: 0.000940
Epoch 3000
   training loss 1.3712297004531138e-05, (6.3013877e-06, 0.058088083, 0.001299161, 0.7280993)
   validation loss 1.77032379724551e-05, (9.932131e-06, 0.16318652, 0.004901138, 0.7280993)
decoder loss ratio: 0.000054, decoder SINDy loss  ratio: 0.000404
THRESHOLDING: 6 active coefficients
Epoch 3100
   training loss 1.1905710380233359e-05, (4.521149e-06, 0.056711983, 0.0012674781, 0.7257814)
   validation loss 1.7314374417765066e-05, (9.520422e-06, 0.1783541, 0.0053613824, 0.7257814)
decoder loss ratio: 0.000051, decoder SINDy loss  ratio: 0.000441
Epoch 3200
   training loss 8.957012141763698e-06, (1.5902118e-06, 0.04778586, 0.0012613615, 0.72406644)
   validation loss 1.0699395716073923e-05, (3.1236139e-06, 0.1670652, 0.0033511822, 0.72406644)
decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000276
Epoch 3300
   training loss 1.2445170796127059e-05, (5.0891076e-06, 0.063513726, 0.0013223938, 0.7223824)
   validation loss 1.7962536730919965e-05, (1.0095193e-05, 0.23053281, 0.0064352043, 0.7223824)
decoder loss ratio: 0.000055, decoder SINDy loss  ratio: 0.000530
Epoch 3400
   training loss 1.0652154742274433e-05, (3.2941844e-06, 0.048903555, 0.001499901, 0.7207981)
   validation loss 1.2910893929074518e-05, (5.2882992e-06, 0.20030615, 0.0041461396, 0.7207981)
decoder loss ratio: 0.000029, decoder SINDy loss  ratio: 0.000341
Epoch 3500
   training loss 2.689085522433743e-05, (1.939838e-05, 0.07598909, 0.0029642382, 0.7196051)
   validation loss 3.521725375321694e-05, (2.7029944e-05, 0.26432928, 0.009912593, 0.7196051)
decoder loss ratio: 0.000146, decoder SINDy loss  ratio: 0.000816
THRESHOLDING: 6 active coefficients
Epoch 3600
   training loss 2.9158565666875802e-05, (2.1653796e-05, 0.07571966, 0.0032740554, 0.71773654)
   validation loss 4.0387931221630424e-05, (3.229276e-05, 0.23045316, 0.00917808, 0.71773654)
decoder loss ratio: 0.000174, decoder SINDy loss  ratio: 0.000756
Epoch 3700
   training loss 1.028132282954175e-05, (2.9391822e-06, 0.058468282, 0.0017821644, 0.71639246)
   validation loss 1.2173190043540671e-05, (4.535944e-06, 0.24458852, 0.004733226, 0.71639246)
decoder loss ratio: 0.000024, decoder SINDy loss  ratio: 0.000390
Epoch 3800
   training loss 1.865851845650468e-05, (1.1175713e-05, 0.07304231, 0.0032704237, 0.71557635)
   validation loss 2.4891072825994343e-05, (1.6797581e-05, 0.3010637, 0.009377288, 0.71557635)
decoder loss ratio: 0.000091, decoder SINDy loss  ratio: 0.000772
Epoch 3900
   training loss 1.1792030818469357e-05, (4.4540284e-06, 0.05791794, 0.0019897744, 0.71390253)
   validation loss 1.4133633158053271e-05, (6.4459136e-06, 0.2247698, 0.005486947, 0.71390253)
decoder loss ratio: 0.000035, decoder SINDy loss  ratio: 0.000452
Epoch 4000
   training loss 1.063953823177144e-05, (3.347161e-06, 0.0625634, 0.0016424771, 0.71281296)
   validation loss 1.2518663424998522e-05, (4.9931996e-06, 0.24348958, 0.0039733397, 0.71281296)
decoder loss ratio: 0.000027, decoder SINDy loss  ratio: 0.000327
THRESHOLDING: 6 active coefficients
Epoch 4100
   training loss 1.0280967217113357e-05, (3.0126962e-06, 0.058794215, 0.001526501, 0.7115621)
   validation loss 1.2028860510326922e-05, (4.528682e-06, 0.22937894, 0.0038455704, 0.7115621)
decoder loss ratio: 0.000024, decoder SINDy loss  ratio: 0.000317
Epoch 4200
   training loss 1.1555983292055316e-05, (4.2636866e-06, 0.073442265, 0.0019076857, 0.71015286)
   validation loss 1.5254245226969942e-05, (7.556315e-06, 0.26427242, 0.0059640245, 0.71015286)
decoder loss ratio: 0.000041, decoder SINDy loss  ratio: 0.000491
Epoch 4300
   training loss 1.4393991477845702e-05, (7.0556325e-06, 0.08007891, 0.0024209304, 0.7096266)
   validation loss 1.8137487131753005e-05, (1.0294402e-05, 0.27758914, 0.0074681914, 0.7096266)
decoder loss ratio: 0.000056, decoder SINDy loss  ratio: 0.000615
Epoch 4400
   training loss 1.01601290225517e-05, (2.937723e-06, 0.063769616, 0.0013739432, 0.70850116)
   validation loss 1.1968697435804643e-05, (4.474973e-06, 0.25167012, 0.004087122, 0.70850116)
decoder loss ratio: 0.000024, decoder SINDy loss  ratio: 0.000337
Epoch 4500
   training loss 8.92988100531511e-06, (1.7193796e-06, 0.06522144, 0.0013008977, 0.7080412)
   validation loss 1.0180476238019764e-05, (2.7583153e-06, 0.24001907, 0.0034174966, 0.7080412)
decoder loss ratio: 0.000015, decoder SINDy loss  ratio: 0.000281
THRESHOLDING: 6 active coefficients
Epoch 4600
   training loss 9.075374691747129e-06, (1.859983e-06, 0.06543996, 0.0014339051, 0.70720017)
   validation loss 1.0405355169496033e-05, (2.9649225e-06, 0.2529519, 0.0036843093, 0.70720017)
decoder loss ratio: 0.000016, decoder SINDy loss  ratio: 0.000303
Epoch 4700
   training loss 1.5569570678053424e-05, (8.253916e-06, 0.09170535, 0.0025236658, 0.7063288)
   validation loss 2.1611460397252813e-05, (1.3658929e-05, 0.30662322, 0.008892448, 0.7063288)
decoder loss ratio: 0.000074, decoder SINDy loss  ratio: 0.000732
Epoch 4800
   training loss 1.574855014041532e-05, (8.4900485e-06, 0.08191248, 0.0020134894, 0.70571536)
   validation loss 1.8316306523047388e-05, (1.0651865e-05, 0.30121627, 0.006072893, 0.70571536)
decoder loss ratio: 0.000058, decoder SINDy loss  ratio: 0.000500
Epoch 4900
   training loss 1.685589631961193e-05, (9.533527e-06, 0.10292787, 0.0026909239, 0.70532775)
   validation loss 2.069497713819146e-05, (1.284478e-05, 0.31745142, 0.007969205, 0.70532775)
decoder loss ratio: 0.000069, decoder SINDy loss  ratio: 0.000656
Epoch 5000
   training loss 9.15456075745169e-06, (1.96073e-06, 0.06665953, 0.001519221, 0.70419085)
   validation loss 1.092698767024558e-05, (3.5099638e-06, 0.23200184, 0.0037511548, 0.70419085)
decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.000309
THRESHOLDING: 6 active coefficients
REFINEMENT
Epoch 0
   training loss 2.1775176719529554e-06, (2.069784e-06, 0.06603926, 0.001077337, 0.70774454)
   validation loss 3.7681431876990246e-06, (3.4583918e-06, 0.24076797, 0.0030975149, 0.70774454)
decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.000255
Epoch 100
   training loss 6.5650469878164586e-06, (6.3912803e-06, 0.06752931, 0.0017376648, 0.72114724)
   validation loss 1.072725990525214e-05, (1.0089249e-05, 0.2505814, 0.0063801087, 0.72114724)
decoder loss ratio: 0.000054, decoder SINDy loss  ratio: 0.000525
Epoch 200
   training loss 5.6414251048408914e-06, (5.4743914e-06, 0.050780874, 0.001670337, 0.72322744)
   validation loss 8.170580258592963e-06, (7.785808e-06, 0.20528187, 0.0038477299, 0.72322744)
decoder loss ratio: 0.000042, decoder SINDy loss  ratio: 0.000317
Epoch 300
   training loss 2.4131711597874528e-06, (2.3292755e-06, 0.032203328, 0.0008389569, 0.7250472)
   validation loss 3.388035111129284e-06, (3.1857353e-06, 0.1647102, 0.002022998, 0.7250472)
decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000167
Epoch 400
   training loss 2.9103482575010275e-06, (2.7979054e-06, 0.03880427, 0.0011244282, 0.72625667)
   validation loss 4.7025223466334864e-06, (4.4059434e-06, 0.19835448, 0.0029657874, 0.72625667)
decoder loss ratio: 0.000024, decoder SINDy loss  ratio: 0.000244
Epoch 500
   training loss 8.900292414182331e-06, (8.771251e-06, 0.032390222, 0.0012904203, 0.7274002)
   validation loss 1.1917203664779663e-05, (1.15345665e-05, 0.17336443, 0.0038263737, 0.7274002)
decoder loss ratio: 0.000062, decoder SINDy loss  ratio: 0.000315
Epoch 600
   training loss 3.5298980947118253e-06, (3.4226027e-06, 0.029141596, 0.0010729532, 0.72814494)
   validation loss 4.6466761887131725e-06, (4.4037124e-06, 0.1506897, 0.0024296364, 0.72814494)
decoder loss ratio: 0.000024, decoder SINDy loss  ratio: 0.000200
Epoch 700
   training loss 1.8515794408813235e-06, (1.7605216e-06, 0.028200865, 0.00091057795, 0.72899175)
   validation loss 3.4492577469791286e-06, (3.194384e-06, 0.15645531, 0.0025487372, 0.72899175)
decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000210
Epoch 800
   training loss 4.039211489725858e-06, (3.9430297e-06, 0.025623173, 0.0009618196, 0.72982574)
   validation loss 5.789640908915317e-06, (5.4746047e-06, 0.14741862, 0.0031503625, 0.72982574)
decoder loss ratio: 0.000030, decoder SINDy loss  ratio: 0.000259
Epoch 900
   training loss 5.563921149587259e-06, (5.4496636e-06, 0.0288612, 0.0011425742, 0.73047)
   validation loss 8.707284905540291e-06, (8.283411e-06, 0.14812885, 0.0042387326, 0.73047)
decoder loss ratio: 0.000045, decoder SINDy loss  ratio: 0.000349
Epoch 1000
   training loss 1.2152042927482398e-06, (1.1290977e-06, 0.023410654, 0.00086106616, 0.7310099)
   validation loss 1.9482399693515617e-06, (1.7660639e-06, 0.14551282, 0.0018217602, 0.7310099)
decoder loss ratio: 0.000010, decoder SINDy loss  ratio: 0.000150
EXPERIMENT 3
TRAINING
Epoch 0
   training loss 0.023141486570239067, (0.022619627, 615.1775, 5.130438, 0.88152945)
   validation loss 0.037305980920791626, (0.035985395, 809.8961, 13.117711, 0.88152945)
decoder loss ratio: 0.194315, decoder SINDy loss  ratio: 1.080143
Epoch 100
   training loss 0.00023802209761925042, (0.00021191695, 0.10092596, 0.06289796, 1.9815363)
   validation loss 0.00032514461781829596, (0.00029304938, 0.31032676, 0.12279878, 1.9815363)
decoder loss ratio: 0.001582, decoder SINDy loss  ratio: 0.010112
Epoch 200
   training loss 3.072011168114841e-05, (1.1033362e-05, 0.0338902, 0.014292233, 1.8257529)
   validation loss 3.543278216966428e-05, (1.4414922e-05, 0.11855731, 0.02760332, 1.8257529)
decoder loss ratio: 0.000078, decoder SINDy loss  ratio: 0.002273
Epoch 300
   training loss 2.5228779122699052e-05, (7.9850915e-06, 0.029968912, 0.00945379, 1.629831)
   validation loss 2.889431743824389e-05, (1.0692755e-05, 0.10332104, 0.01903254, 1.629831)
decoder loss ratio: 0.000058, decoder SINDy loss  ratio: 0.001567
Epoch 400
   training loss 1.7707092411001213e-05, (2.2539643e-06, 0.02673441, 0.0066074743, 1.4792382)
   validation loss 1.9549226635717787e-05, (3.4584803e-06, 0.09910012, 0.01298365, 1.4792382)
decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.001069
Epoch 500
   training loss 2.454976856824942e-05, (1.05314575e-05, 0.030697225, 0.0058576595, 1.3432546)
   validation loss 2.9214086680440232e-05, (1.4596847e-05, 0.10469518, 0.011846947, 1.3432546)
decoder loss ratio: 0.000079, decoder SINDy loss  ratio: 0.000976
THRESHOLDING: 34 active coefficients
Epoch 600
   training loss 6.061906606191769e-05, (4.7063695e-05, 0.042313233, 0.011260312, 1.242934)
   validation loss 8.306457311846316e-05, (6.7999696e-05, 0.11996751, 0.02635539, 1.242934)
decoder loss ratio: 0.000367, decoder SINDy loss  ratio: 0.002170
Epoch 700
   training loss 6.111439142841846e-05, (4.8195117e-05, 0.049369946, 0.010456867, 1.1873589)
   validation loss 8.664977212902158e-05, (7.2161856e-05, 0.13350593, 0.02614329, 1.1873589)
decoder loss ratio: 0.000390, decoder SINDy loss  ratio: 0.002153
Epoch 800
   training loss 3.785623994190246e-05, (2.576171e-05, 0.046488654, 0.0073889857, 1.1355631)
   validation loss 4.9400372517993674e-05, (3.6204012e-05, 0.1380695, 0.01840731, 1.1355631)
decoder loss ratio: 0.000195, decoder SINDy loss  ratio: 0.001516
Epoch 900
   training loss 3.9784208638593554e-05, (2.8406197e-05, 0.039954588, 0.003848893, 1.0993122)
   validation loss 5.506841989699751e-05, (4.2958116e-05, 0.11624677, 0.011171842, 1.0993122)
decoder loss ratio: 0.000232, decoder SINDy loss  ratio: 0.000920
Epoch 1000
   training loss 4.828465171158314e-05, (3.6997157e-05, 0.05716199, 0.004925521, 1.0794942)
   validation loss 6.288105942076072e-05, (5.0717794e-05, 0.15780938, 0.013683223, 1.0794942)
decoder loss ratio: 0.000274, decoder SINDy loss  ratio: 0.001127
THRESHOLDING: 22 active coefficients
Epoch 1100
   training loss 2.6665913537726738e-05, (1.5480324e-05, 0.04327594, 0.005137472, 1.0671842)
   validation loss 3.4961958590429276e-05, (2.3070264e-05, 0.12706149, 0.012198526, 1.0671842)
decoder loss ratio: 0.000125, decoder SINDy loss  ratio: 0.001004
Epoch 1200
   training loss 1.6119511201395653e-05, (5.1855795e-06, 0.046906035, 0.004060524, 1.052788)
   validation loss 2.365987893426791e-05, (1.1758597e-05, 0.15122466, 0.013734014, 1.052788)
decoder loss ratio: 0.000063, decoder SINDy loss  ratio: 0.001131
Epoch 1300
   training loss 3.181894862791523e-05, (2.0773867e-05, 0.050026815, 0.006195411, 1.0425544)
   validation loss 4.4010863348376006e-05, (3.2193846e-05, 0.14852479, 0.013914752, 1.0425544)
decoder loss ratio: 0.000174, decoder SINDy loss  ratio: 0.001146
Epoch 1400
   training loss 2.678099917829968e-05, (1.6025031e-05, 0.06394353, 0.0042940946, 1.032656)
   validation loss 2.9651044314960018e-05, (1.8483182e-05, 0.1616111, 0.008413025, 1.032656)
decoder loss ratio: 0.000100, decoder SINDy loss  ratio: 0.000693
Epoch 1500
   training loss 2.3102747945813462e-05, (1.2401111e-05, 0.06764419, 0.004563441, 1.0245293)
   validation loss 2.6272275135852396e-05, (1.5196365e-05, 0.15315552, 0.00830618, 1.0245293)
decoder loss ratio: 0.000082, decoder SINDy loss  ratio: 0.000684
THRESHOLDING: 20 active coefficients
Epoch 1600
   training loss 3.160452251904644e-05, (2.089509e-05, 0.077149354, 0.0053307656, 1.0176357)
   validation loss 3.35636614181567e-05, (2.2463806e-05, 0.17007336, 0.0092349835, 1.0176357)
decoder loss ratio: 0.000121, decoder SINDy loss  ratio: 0.000760
Epoch 1700
   training loss 1.8274644389748573e-05, (7.664978e-06, 0.0780675, 0.004921141, 1.0117552)
   validation loss 2.0752388081746176e-05, (9.8332275e-06, 0.15919249, 0.0080160955, 1.0117552)
decoder loss ratio: 0.000053, decoder SINDy loss  ratio: 0.000660
Epoch 1800
   training loss 3.246771666454151e-05, (2.178764e-05, 0.089560926, 0.0061578397, 1.0064293)
   validation loss 3.893601751769893e-05, (2.7737808e-05, 0.17464645, 0.011339177, 1.0064293)
decoder loss ratio: 0.000150, decoder SINDy loss  ratio: 0.000934
Epoch 1900
   training loss 1.2750711903208867e-05, (2.3133591e-06, 0.081487186, 0.004239145, 1.0013438)
   validation loss 1.4911884136381559e-05, (4.0759173e-06, 0.17139924, 0.008225287, 1.0013438)
decoder loss ratio: 0.000022, decoder SINDy loss  ratio: 0.000677
Epoch 2000
   training loss 2.3201791918836534e-05, (1.2656274e-05, 0.08820996, 0.0058297627, 0.9962542)
   validation loss 2.8004724299535155e-05, (1.6828397e-05, 0.1959051, 0.01213785, 0.9962542)
decoder loss ratio: 0.000091, decoder SINDy loss  ratio: 0.000999
THRESHOLDING: 18 active coefficients
Epoch 2100
   training loss 1.702710687823128e-05, (6.65736e-06, 0.08478885, 0.00467874, 0.9901873)
   validation loss 2.101214340655133e-05, (1.0075507e-05, 0.20773754, 0.010347628, 0.9901873)
decoder loss ratio: 0.000054, decoder SINDy loss  ratio: 0.000852
Epoch 2200
   training loss 1.555985727463849e-05, (5.208104e-06, 0.08660821, 0.0048167384, 0.98700804)
   validation loss 1.824015998863615e-05, (7.3844485e-06, 0.21206807, 0.0098563135, 0.98700804)
decoder loss ratio: 0.000040, decoder SINDy loss  ratio: 0.000812
Epoch 2300
   training loss 1.6272419088636525e-05, (5.941135e-06, 0.08804354, 0.004903719, 0.98409134)
   validation loss 1.999504820560105e-05, (9.158266e-06, 0.21973027, 0.009958698, 0.98409134)
decoder loss ratio: 0.000049, decoder SINDy loss  ratio: 0.000820
Epoch 2400
   training loss 4.7785772039787844e-05, (3.7146252e-05, 0.12206913, 0.00829505, 0.98100126)
   validation loss 6.521157047245651e-05, (5.3315824e-05, 0.27069142, 0.02085734, 0.98100126)
decoder loss ratio: 0.000288, decoder SINDy loss  ratio: 0.001717
Epoch 2500
   training loss 1.2610469639184885e-05, (2.4534688e-06, 0.08808843, 0.0037730762, 0.9779694)
   validation loss 1.4305936929304153e-05, (3.7702684e-06, 0.22245668, 0.007559749, 0.9779694)
decoder loss ratio: 0.000020, decoder SINDy loss  ratio: 0.000622
THRESHOLDING: 17 active coefficients
Epoch 2600
   training loss 1.8778904632199556e-05, (8.600937e-06, 0.08982396, 0.004110874, 0.9766881)
   validation loss 2.1468207705765963e-05, (1.0706914e-05, 0.2578104, 0.009944141, 0.9766881)
decoder loss ratio: 0.000058, decoder SINDy loss  ratio: 0.000819
Epoch 2700
   training loss 1.624357173568569e-05, (6.0732045e-06, 0.09596034, 0.0042386297, 0.9746505)
   validation loss 1.9776320186792873e-05, (8.95345e-06, 0.2693394, 0.010763657, 0.9746505)
decoder loss ratio: 0.000048, decoder SINDy loss  ratio: 0.000886
Epoch 2800
   training loss 1.671725112828426e-05, (6.6784914e-06, 0.08712524, 0.0031403387, 0.97247255)
   validation loss 1.958381835720502e-05, (9.002945e-06, 0.25173208, 0.008561477, 0.97247255)
decoder loss ratio: 0.000049, decoder SINDy loss  ratio: 0.000705
Epoch 2900
   training loss 2.185138509958051e-05, (1.1703114e-05, 0.09133593, 0.004488311, 0.9699441)
   validation loss 2.6447840355103835e-05, (1.5613108e-05, 0.28209043, 0.011352911, 0.9699441)
decoder loss ratio: 0.000084, decoder SINDy loss  ratio: 0.000935
Epoch 3000
   training loss 1.4093195204623044e-05, (4.087063e-06, 0.08939221, 0.0032290674, 0.9683226)
   validation loss 1.662751310504973e-05, (6.10731e-06, 0.24834572, 0.008369776, 0.9683226)
decoder loss ratio: 0.000033, decoder SINDy loss  ratio: 0.000689
THRESHOLDING: 16 active coefficients
Epoch 3100
   training loss 1.1675277164613362e-05, (1.6672896e-06, 0.088619314, 0.0034628138, 0.9661706)
   validation loss 1.3872118870494887e-05, (3.342652e-06, 0.2599126, 0.008677616, 0.9661706)
decoder loss ratio: 0.000018, decoder SINDy loss  ratio: 0.000715
Epoch 3200
   training loss 2.225044954684563e-05, (1.2218683e-05, 0.093540944, 0.003920698, 0.96396977)
   validation loss 2.597495767986402e-05, (1.5375052e-05, 0.274495, 0.009602085, 0.96396977)
decoder loss ratio: 0.000083, decoder SINDy loss  ratio: 0.000791
Epoch 3300
   training loss 1.6023299394873902e-05, (6.026381e-06, 0.09834435, 0.0037761051, 0.96193093)
   validation loss 2.038103593804408e-05, (9.661851e-06, 0.2751087, 0.010998754, 0.96193093)
decoder loss ratio: 0.000052, decoder SINDy loss  ratio: 0.000906
Epoch 3400
   training loss 1.4247842045733705e-05, (4.2995434e-06, 0.10086733, 0.0034843541, 0.9599863)
   validation loss 1.657559369050432e-05, (6.2289255e-06, 0.27817678, 0.007468048, 0.9599863)
decoder loss ratio: 0.000034, decoder SINDy loss  ratio: 0.000615
Epoch 3500
   training loss 1.4323497453005984e-05, (4.3958735e-06, 0.1034034, 0.003467809, 0.9580844)
   validation loss 1.6715048332116567e-05, (6.368167e-06, 0.26560485, 0.007660377, 0.9580844)
decoder loss ratio: 0.000034, decoder SINDy loss  ratio: 0.000631
THRESHOLDING: 16 active coefficients
Epoch 3600
   training loss 2.1518542780540884e-05, (1.159211e-05, 0.11105913, 0.0036584712, 0.9560587)
   validation loss 2.447470251354389e-05, (1.4076448e-05, 0.28960285, 0.008376672, 0.9560587)
decoder loss ratio: 0.000076, decoder SINDy loss  ratio: 0.000690
Epoch 3700
   training loss 2.484815922798589e-05, (1.4803213e-05, 0.115611196, 0.0050301985, 0.9541927)
   validation loss 2.9022434318903834e-05, (1.8430153e-05, 0.33854094, 0.010503533, 0.9541927)
decoder loss ratio: 0.000100, decoder SINDy loss  ratio: 0.000865
Epoch 3800
   training loss 1.8211434507975355e-05, (8.251149e-06, 0.1110918, 0.004359002, 0.9524385)
   validation loss 2.1497447960427962e-05, (1.105844e-05, 0.31027466, 0.009146235, 0.9524385)
decoder loss ratio: 0.000060, decoder SINDy loss  ratio: 0.000753
Epoch 3900
   training loss 1.4147818546916824e-05, (4.270893e-06, 0.11238716, 0.0036493607, 0.95119894)
   validation loss 1.6637623048154637e-05, (6.3546754e-06, 0.30855078, 0.0077095726, 0.95119894)
decoder loss ratio: 0.000034, decoder SINDy loss  ratio: 0.000635
Epoch 4000
   training loss 1.26985578390304e-05, (2.8395568e-06, 0.118982844, 0.0036334554, 0.94956553)
   validation loss 1.5046346561575774e-05, (4.7956246e-06, 0.30813465, 0.007550671, 0.94956553)
decoder loss ratio: 0.000026, decoder SINDy loss  ratio: 0.000622
THRESHOLDING: 16 active coefficients
Epoch 4100
   training loss 2.0379131456138566e-05, (1.0458986e-05, 0.116000034, 0.0044051055, 0.9479636)
   validation loss 2.3026186681818217e-05, (1.2709969e-05, 0.32137188, 0.008365817, 0.9479636)
decoder loss ratio: 0.000069, decoder SINDy loss  ratio: 0.000689
Epoch 4200
   training loss 1.1319149052724242e-05, (1.5068965e-06, 0.11775806, 0.003453299, 0.9466922)
   validation loss 1.3907088032283355e-05, (3.6780461e-06, 0.2992968, 0.0076211984, 0.9466922)
decoder loss ratio: 0.000020, decoder SINDy loss  ratio: 0.000628
Epoch 4300
   training loss 1.1012241884600371e-05, (1.1972131e-06, 0.1230081, 0.0036310938, 0.9451919)
   validation loss 1.2323534974711947e-05, (2.233824e-06, 0.27911672, 0.0063779177, 0.9451919)
decoder loss ratio: 0.000012, decoder SINDy loss  ratio: 0.000525
Epoch 4400
   training loss 1.632009843888227e-05, (6.4927885e-06, 0.124042906, 0.0038606024, 0.944125)
   validation loss 1.941448135767132e-05, (9.197545e-06, 0.29774594, 0.0077568544, 0.944125)
decoder loss ratio: 0.000050, decoder SINDy loss  ratio: 0.000639
Epoch 4500
   training loss 2.3643468011869118e-05, (1.3799316e-05, 0.14176191, 0.0041376734, 0.9430385)
   validation loss 2.9739743695245124e-05, (1.9251966e-05, 0.34065545, 0.010573934, 0.9430385)
decoder loss ratio: 0.000104, decoder SINDy loss  ratio: 0.000871
THRESHOLDING: 16 active coefficients
Epoch 4600
   training loss 2.092734575853683e-05, (1.10625915e-05, 0.15528844, 0.0044832267, 0.9416432)
   validation loss 2.5738545446074568e-05, (1.5299602e-05, 0.346282, 0.010225118, 0.9416432)
decoder loss ratio: 0.000083, decoder SINDy loss  ratio: 0.000842
Epoch 4700
   training loss 1.876347596407868e-05, (8.892288e-06, 0.14701907, 0.004638049, 0.94073844)
   validation loss 2.2437739971792325e-05, (1.1815624e-05, 0.3535033, 0.012147324, 0.94073844)
decoder loss ratio: 0.000064, decoder SINDy loss  ratio: 0.001000
Epoch 4800
   training loss 1.294436697207857e-05, (3.1632342e-06, 0.13527717, 0.0038802114, 0.93931127)
   validation loss 1.4101566193858162e-05, (4.0245054e-06, 0.28894186, 0.006839482, 0.93931127)
decoder loss ratio: 0.000022, decoder SINDy loss  ratio: 0.000563
Epoch 4900
   training loss 1.8589544197311625e-05, (8.790744e-06, 0.14720851, 0.004131106, 0.93856895)
   validation loss 2.09649315365823e-05, (1.0839866e-05, 0.30762, 0.0073937653, 0.93856895)
decoder loss ratio: 0.000059, decoder SINDy loss  ratio: 0.000609
Epoch 5000
   training loss 1.6024609067244455e-05, (6.1796286e-06, 0.14797525, 0.004678044, 0.93771756)
   validation loss 1.946082920767367e-05, (9.267575e-06, 0.3340468, 0.008160783, 0.93771756)
decoder loss ratio: 0.000050, decoder SINDy loss  ratio: 0.000672
THRESHOLDING: 16 active coefficients
REFINEMENT
Epoch 0
   training loss 2.7212586246605497e-06, (2.3895004e-06, 0.12913609, 0.0033175824, 0.9442304)
   validation loss 4.53488928542356e-06, (3.8874173e-06, 0.27629316, 0.0064747217, 0.9442304)
decoder loss ratio: 0.000021, decoder SINDy loss  ratio: 0.000533
Epoch 100
   training loss 7.234158601931995e-06, (6.9611624e-06, 0.08784174, 0.0027299619, 0.9868097)
   validation loss 9.450195648241788e-06, (8.882331e-06, 0.24585183, 0.005678652, 0.9868097)
decoder loss ratio: 0.000048, decoder SINDy loss  ratio: 0.000468
Epoch 200
   training loss 2.8604235922102816e-06, (2.6997432e-06, 0.065548055, 0.0016068036, 0.9956331)
   validation loss 3.64629295290797e-06, (3.292781e-06, 0.21357861, 0.003535119, 0.9956331)
decoder loss ratio: 0.000018, decoder SINDy loss  ratio: 0.000291
Epoch 300
   training loss 2.59419380199688e-06, (2.4661913e-06, 0.05067125, 0.0012800245, 1.0011991)
   validation loss 3.984059731010348e-06, (3.6743559e-06, 0.19565384, 0.0030970399, 1.0011991)
decoder loss ratio: 0.000020, decoder SINDy loss  ratio: 0.000255
Epoch 400
   training loss 2.379679699515691e-06, (2.249128e-06, 0.05992368, 0.001305515, 1.0051777)
   validation loss 4.142844773014076e-06, (3.691143e-06, 0.22500211, 0.0045170183, 1.0051777)
decoder loss ratio: 0.000020, decoder SINDy loss  ratio: 0.000372
Epoch 500
   training loss 5.373846306611085e-06, (5.1890506e-06, 0.05694217, 0.0018479588, 1.0079415)
   validation loss 9.660905561759137e-06, (9.19461e-06, 0.2204898, 0.0046629515, 1.0079415)
decoder loss ratio: 0.000050, decoder SINDy loss  ratio: 0.000384
Epoch 600
   training loss 4.328224349592347e-06, (4.1849953e-06, 0.047931682, 0.0014322926, 1.0104091)
   validation loss 6.213400865817675e-06, (5.887417e-06, 0.19620585, 0.0032598393, 1.0104091)
decoder loss ratio: 0.000032, decoder SINDy loss  ratio: 0.000268
Epoch 700
   training loss 8.528504622518085e-06, (8.357555e-06, 0.06041473, 0.0017094987, 1.0121002)
   validation loss 1.2520284144557081e-05, (1.2022763e-05, 0.22086702, 0.00497521, 1.0121002)
decoder loss ratio: 0.000065, decoder SINDy loss  ratio: 0.000410
Epoch 800
   training loss 6.805699285905575e-06, (6.6299444e-06, 0.06544759, 0.00175755, 1.0141149)
   validation loss 9.150808182312176e-06, (8.70291e-06, 0.194962, 0.004478983, 1.0141149)
decoder loss ratio: 0.000047, decoder SINDy loss  ratio: 0.000369
Epoch 900
   training loss 4.2074525481439196e-06, (4.0708123e-06, 0.05507132, 0.0013664004, 1.0153025)
   validation loss 6.665655746473931e-06, (6.3446505e-06, 0.19683342, 0.0032100524, 1.0153025)
decoder loss ratio: 0.000034, decoder SINDy loss  ratio: 0.000264
Epoch 1000
   training loss 8.351012183993589e-06, (8.209945e-06, 0.06273335, 0.001410669, 1.016277)
   validation loss 1.2100824278604705e-05, (1.1418907e-05, 0.22819827, 0.006819173, 1.016277)
decoder loss ratio: 0.000062, decoder SINDy loss  ratio: 0.000562
EXPERIMENT 4
TRAINING
Epoch 0
   training loss 0.02441265620291233, (0.023967477, 241.1112, 4.366528, 0.8526562)
   validation loss 0.03869691491127014, (0.037474763, 230.82002, 12.13625, 0.8526562)
decoder loss ratio: 0.202358, decoder SINDy loss  ratio: 0.999327
Epoch 100
   training loss 7.294168608495966e-05, (5.2067688e-05, 0.055850923, 0.026967362, 1.8177263)
   validation loss 7.130645826691762e-05, (4.6420595e-05, 0.21455985, 0.06708601, 1.8177263)
decoder loss ratio: 0.000251, decoder SINDy loss  ratio: 0.005524
Epoch 200
   training loss 3.0384609999600798e-05, (1.3340103e-05, 0.020607706, 0.009574072, 1.6087102)
   validation loss 3.5886700061382726e-05, (1.7482023e-05, 0.0859415, 0.023175767, 1.6087102)
decoder loss ratio: 0.000094, decoder SINDy loss  ratio: 0.001908
Epoch 300
   training loss 4.141551471548155e-05, (2.5575402e-05, 0.023131564, 0.00970288, 1.4869825)
   validation loss 4.304645335651003e-05, (2.5594607e-05, 0.08533931, 0.025820222, 1.4869825)
decoder loss ratio: 0.000138, decoder SINDy loss  ratio: 0.002126
Epoch 400
   training loss 2.9202690711827017e-05, (1.4651778e-05, 0.021267394, 0.0063790856, 1.3913004)
   validation loss 3.091635153396055e-05, (1.5487909e-05, 0.07906711, 0.015154367, 1.3913004)
decoder loss ratio: 0.000084, decoder SINDy loss  ratio: 0.001248
Epoch 500
   training loss 2.030115865636617e-05, (6.727771e-06, 0.022899522, 0.004478327, 1.3125556)
   validation loss 2.409644002909772e-05, (1.0000268e-05, 0.07545134, 0.009706156, 1.3125556)
decoder loss ratio: 0.000054, decoder SINDy loss  ratio: 0.000799
THRESHOLDING: 28 active coefficients
Epoch 600
   training loss 1.7425123587599955e-05, (4.616927e-06, 0.022466997, 0.0041529704, 1.23929)
   validation loss 1.858355972217396e-05, (5.3012664e-06, 0.07475075, 0.008893934, 1.23929)
decoder loss ratio: 0.000029, decoder SINDy loss  ratio: 0.000732
Epoch 700
   training loss 3.949858364649117e-05, (2.6939058e-05, 0.03161222, 0.0059940713, 1.1960117)
   validation loss 4.897667167824693e-05, (3.5900714e-05, 0.08725999, 0.011158408, 1.1960117)
decoder loss ratio: 0.000194, decoder SINDy loss  ratio: 0.000919
Epoch 800
   training loss 1.9481802155496553e-05, (7.4561676e-06, 0.028829342, 0.003886133, 1.1637022)
   validation loss 2.3080490791471675e-05, (1.060177e-05, 0.077630825, 0.008416996, 1.1637022)
decoder loss ratio: 0.000057, decoder SINDy loss  ratio: 0.000693
Epoch 900
   training loss 2.2913449356565252e-05, (1.1092414e-05, 0.034936234, 0.0043753292, 1.1383502)
   validation loss 2.9421829822240397e-05, (1.6719354e-05, 0.09912838, 0.013189741, 1.1383502)
decoder loss ratio: 0.000090, decoder SINDy loss  ratio: 0.001086
Epoch 1000
   training loss 8.971803617896512e-05, (7.7793666e-05, 0.052788865, 0.0075214393, 1.1172224)
   validation loss 9.418625995749608e-05, (8.133848e-05, 0.13213125, 0.016755534, 1.1172224)
decoder loss ratio: 0.000439, decoder SINDy loss  ratio: 0.001380
THRESHOLDING: 19 active coefficients
Epoch 1100
   training loss 1.62700471264543e-05, (4.9534874e-06, 0.046188623, 0.0037722606, 1.0939335)
   validation loss 1.9187922589480877e-05, (7.3138876e-06, 0.12652503, 0.009346999, 1.0939335)
decoder loss ratio: 0.000039, decoder SINDy loss  ratio: 0.000770
Epoch 1200
   training loss 1.668236291152425e-05, (5.524031e-06, 0.04026201, 0.003519982, 1.0806334)
   validation loss 2.038065213127993e-05, (8.7236385e-06, 0.13759904, 0.008506801, 1.0806334)
decoder loss ratio: 0.000047, decoder SINDy loss  ratio: 0.000700
Epoch 1300
   training loss 3.1212173780659214e-05, (2.0125372e-05, 0.043495927, 0.004035637, 1.0683239)
   validation loss 3.905186167685315e-05, (2.7224343e-05, 0.14677648, 0.011442798, 1.0683239)
decoder loss ratio: 0.000147, decoder SINDy loss  ratio: 0.000942
Epoch 1400
   training loss 2.240378307760693e-05, (1.1455496e-05, 0.044108715, 0.0036294174, 1.0585346)
   validation loss 2.8435057174647227e-05, (1.6932447e-05, 0.14906393, 0.0091726575, 1.0585346)
decoder loss ratio: 0.000091, decoder SINDy loss  ratio: 0.000755
Epoch 1500
   training loss 1.2075658560206648e-05, (1.3143319e-06, 0.036979917, 0.0025497866, 1.0506349)
   validation loss 1.4503784768749028e-05, (3.2586306e-06, 0.14945468, 0.007388059, 1.0506349)
decoder loss ratio: 0.000018, decoder SINDy loss  ratio: 0.000608
THRESHOLDING: 16 active coefficients
Epoch 1600
   training loss 2.9930470191175118e-05, (1.910059e-05, 0.04589008, 0.003540493, 1.0475831)
   validation loss 3.75903255189769e-05, (2.6032752e-05, 0.18246436, 0.010817444, 1.0475831)
decoder loss ratio: 0.000141, decoder SINDy loss  ratio: 0.000891
Epoch 1700
   training loss 1.5995599824236706e-05, (5.3241265e-06, 0.04186836, 0.0025152876, 1.0419945)
   validation loss 2.0324732759036124e-05, (9.170476e-06, 0.1729729, 0.007343119, 1.0419945)
decoder loss ratio: 0.000050, decoder SINDy loss  ratio: 0.000605
Epoch 1800
   training loss 1.7226919226231985e-05, (6.5798404e-06, 0.043510575, 0.0027439133, 1.0372688)
   validation loss 2.0984485672670417e-05, (9.84372e-06, 0.17741115, 0.0076807877, 1.0372688)
decoder loss ratio: 0.000053, decoder SINDy loss  ratio: 0.000632
Epoch 1900
   training loss 1.560919190524146e-05, (5.06392e-06, 0.04390496, 0.002259394, 1.0319332)
   validation loss 1.9743192751775496e-05, (8.657183e-06, 0.17782377, 0.0076667895, 1.0319332)
decoder loss ratio: 0.000047, decoder SINDy loss  ratio: 0.000631
Epoch 2000
   training loss 1.5062389138620347e-05, (4.521254e-06, 0.048937663, 0.0026445556, 1.0276679)
   validation loss 1.76537869265303e-05, (6.7082537e-06, 0.17396113, 0.0066885324, 1.0276679)
decoder loss ratio: 0.000036, decoder SINDy loss  ratio: 0.000551
THRESHOLDING: 15 active coefficients
Epoch 2100
   training loss 1.3024551662965678e-05, (2.611677e-06, 0.045719083, 0.0019438365, 1.0218492)
   validation loss 1.5502004316658713e-05, (4.723849e-06, 0.16790003, 0.0055966447, 1.0218492)
decoder loss ratio: 0.000026, decoder SINDy loss  ratio: 0.000461
Epoch 2200
   training loss 1.1668576917145401e-05, (1.3086741e-06, 0.04655684, 0.001767124, 1.018319)
   validation loss 1.3789069271297194e-05, (3.0371723e-06, 0.1758569, 0.0056870733, 1.018319)
decoder loss ratio: 0.000016, decoder SINDy loss  ratio: 0.000468
Epoch 2300
   training loss 1.4566116078640334e-05, (4.1870685e-06, 0.056044888, 0.002320427, 1.0147005)
   validation loss 1.852672539826017e-05, (7.5346984e-06, 0.21045126, 0.008450222, 1.0147005)
decoder loss ratio: 0.000041, decoder SINDy loss  ratio: 0.000696
Epoch 2400
   training loss 1.9365907064639032e-05, (8.906836e-06, 0.07098508, 0.0034227534, 1.0116795)
   validation loss 2.3592107027070597e-05, (1.26415325e-05, 0.20205064, 0.008337803, 1.0116795)
decoder loss ratio: 0.000068, decoder SINDy loss  ratio: 0.000687
Epoch 2500
   training loss 1.3231676348368637e-05, (2.928331e-06, 0.056496453, 0.0021706293, 1.0086282)
   validation loss 1.7262629626202397e-05, (6.4987094e-06, 0.19504221, 0.0067763804, 1.0086282)
decoder loss ratio: 0.000035, decoder SINDy loss  ratio: 0.000558
THRESHOLDING: 15 active coefficients
Epoch 2600
   training loss 1.4265904610510916e-05, (4.002572e-06, 0.0640846, 0.002068782, 1.0056455)
   validation loss 1.7730901163304225e-05, (7.043153e-06, 0.19577844, 0.006312943, 1.0056455)
decoder loss ratio: 0.000038, decoder SINDy loss  ratio: 0.000520
Epoch 2700
   training loss 1.3649948414240498e-05, (3.4074387e-06, 0.061440427, 0.0020983557, 1.0032674)
   validation loss 1.6919890185818076e-05, (6.2341633e-06, 0.20240209, 0.006530532, 1.0032674)
decoder loss ratio: 0.000034, decoder SINDy loss  ratio: 0.000538
Epoch 2800
   training loss 1.540816083434038e-05, (5.1955003e-06, 0.058039863, 0.0020551975, 1.0007141)
   validation loss 2.1295571059454232e-05, (1.0490061e-05, 0.2240068, 0.007983689, 1.0007141)
decoder loss ratio: 0.000057, decoder SINDy loss  ratio: 0.000657
Epoch 2900
   training loss 1.2927785064675845e-05, (2.7489127e-06, 0.06296688, 0.0020149376, 0.9977379)
   validation loss 1.4721599654876627e-05, (4.163073e-06, 0.22431102, 0.0058114794, 0.9977379)
decoder loss ratio: 0.000022, decoder SINDy loss  ratio: 0.000479
Epoch 3000
   training loss 1.4178365745465271e-05, (3.9796696e-06, 0.06608641, 0.002443105, 0.99543864)
   validation loss 1.7847507479018532e-05, (7.2366774e-06, 0.24041313, 0.0065644453, 0.99543864)
decoder loss ratio: 0.000039, decoder SINDy loss  ratio: 0.000541
THRESHOLDING: 15 active coefficients
Epoch 3100
   training loss 1.753015021677129e-05, (7.3962938e-06, 0.06639863, 0.0020810836, 0.99257493)
   validation loss 2.1204286895226687e-05, (1.07411015e-05, 0.22228827, 0.005374369, 0.99257493)
decoder loss ratio: 0.000058, decoder SINDy loss  ratio: 0.000443
Epoch 3200
   training loss 2.7031212084693834e-05, (1.6800248e-05, 0.08698144, 0.0032615396, 0.990481)
   validation loss 3.187820402672514e-05, (2.1200889e-05, 0.26495987, 0.007725044, 0.990481)
decoder loss ratio: 0.000114, decoder SINDy loss  ratio: 0.000636
Epoch 3300
   training loss 1.509054891357664e-05, (4.988175e-06, 0.069871955, 0.0021367287, 0.9888701)
   validation loss 1.948627868841868e-05, (8.925108e-06, 0.24517588, 0.006724701, 0.9888701)
decoder loss ratio: 0.000048, decoder SINDy loss  ratio: 0.000554
Epoch 3400
   training loss 4.5457782107405365e-05, (3.5113e-05, 0.09527544, 0.0047847154, 0.9866311)
   validation loss 5.956921449978836e-05, (4.848097e-05, 0.28993618, 0.012219317, 0.9866311)
decoder loss ratio: 0.000262, decoder SINDy loss  ratio: 0.001006
Epoch 3500
   training loss 1.202150815515779e-05, (1.9622598e-06, 0.06277611, 0.0020943622, 0.98498124)
   validation loss 1.3858629245078191e-05, (3.4645118e-06, 0.25443152, 0.0054430473, 0.98498124)
decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.000448
THRESHOLDING: 15 active coefficients
Epoch 3600
   training loss 1.2178110409877263e-05, (2.1058022e-06, 0.07269732, 0.0024420721, 0.9828101)
   validation loss 1.3863274944014847e-05, (3.464606e-06, 0.2874784, 0.005705677, 0.9828101)
decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.000470
Epoch 3700
   training loss 1.3068194675724953e-05, (3.0583292e-06, 0.063790254, 0.0020219437, 0.9807671)
   validation loss 1.384018651151564e-05, (3.545424e-06, 0.26969138, 0.00487092, 0.9807671)
decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.000401
Epoch 3800
   training loss 1.1337781870679464e-05, (1.336061e-06, 0.06712693, 0.0021064933, 0.97910714)
   validation loss 1.238606455444824e-05, (2.0926927e-06, 0.29857838, 0.0050229994, 0.97910714)
decoder loss ratio: 0.000011, decoder SINDy loss  ratio: 0.000414
Epoch 3900
   training loss 1.2466339285310823e-05, (2.4643196e-06, 0.0673649, 0.0022648065, 0.97755396)
   validation loss 1.4387576811714098e-05, (4.0350137e-06, 0.3122416, 0.005770245, 0.97755396)
decoder loss ratio: 0.000022, decoder SINDy loss  ratio: 0.000475
Epoch 4000
   training loss 2.187133941333741e-05, (1.1869566e-05, 0.080078244, 0.0024231249, 0.97594625)
   validation loss 2.4223263608291745e-05, (1.3858768e-05, 0.34175724, 0.006050343, 0.97594625)
decoder loss ratio: 0.000075, decoder SINDy loss  ratio: 0.000498
THRESHOLDING: 15 active coefficients
Epoch 4100
   training loss 2.081222555716522e-05, (1.0663087e-05, 0.095404185, 0.0040036417, 0.9748776)
   validation loss 2.7278993002255447e-05, (1.6337384e-05, 0.3943926, 0.01192833, 0.9748776)
decoder loss ratio: 0.000088, decoder SINDy loss  ratio: 0.000982
Epoch 4200
   training loss 1.239420635101851e-05, (2.472848e-06, 0.073519, 0.0018873422, 0.9732624)
   validation loss 1.3361995115701575e-05, (3.1716506e-06, 0.2943662, 0.004577208, 0.9732624)
decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000377
Epoch 4300
   training loss 1.361977047054097e-05, (3.6749382e-06, 0.0778641, 0.0022367137, 0.9721161)
   validation loss 1.5007386537035927e-05, (4.6977098e-06, 0.31940466, 0.005885168, 0.9721161)
decoder loss ratio: 0.000025, decoder SINDy loss  ratio: 0.000485
Epoch 4400
   training loss 1.4019418813404627e-05, (4.1142575e-06, 0.07815818, 0.0019774116, 0.97074205)
   validation loss 1.650167723710183e-05, (6.220611e-06, 0.36409512, 0.0057364698, 0.97074205)
decoder loss ratio: 0.000034, decoder SINDy loss  ratio: 0.000472
Epoch 4500
   training loss 1.3901685633754823e-05, (3.994312e-06, 0.076865986, 0.002076725, 0.96997017)
   validation loss 1.4851358173473272e-05, (4.566113e-06, 0.34770823, 0.0058554425, 0.96997017)
decoder loss ratio: 0.000025, decoder SINDy loss  ratio: 0.000482
THRESHOLDING: 14 active coefficients
Epoch 4600
   training loss 1.4183447092364077e-05, (4.2589877e-06, 0.08415518, 0.0020821542, 0.97162443)
   validation loss 1.5736955901957117e-05, (5.549165e-06, 0.35963422, 0.00471547, 0.97162443)
decoder loss ratio: 0.000030, decoder SINDy loss  ratio: 0.000388
Epoch 4700
   training loss 1.1100907613581512e-05, (1.2184042e-06, 0.0763475, 0.0018959729, 0.9692907)
   validation loss 1.208955654874444e-05, (1.9540532e-06, 0.37465292, 0.00442597, 0.9692907)
decoder loss ratio: 0.000011, decoder SINDy loss  ratio: 0.000364
Epoch 4800
   training loss 2.0766263332916424e-05, (1.0814454e-05, 0.104904205, 0.0027396104, 0.96778494)
   validation loss 2.444173333060462e-05, (1.4140062e-05, 0.43820307, 0.0062382184, 0.96778494)
decoder loss ratio: 0.000076, decoder SINDy loss  ratio: 0.000514
Epoch 4900
   training loss 2.1680520148947835e-05, (1.1736826e-05, 0.09161838, 0.0028194962, 0.9661744)
   validation loss 2.5885270588332787e-05, (1.5566386e-05, 0.48372653, 0.006571416, 0.9661744)
decoder loss ratio: 0.000084, decoder SINDy loss  ratio: 0.000541
Epoch 5000
   training loss 1.8601323972688988e-05, (8.590273e-06, 0.099870265, 0.0036811144, 0.96429384)
   validation loss 2.4415670850430615e-05, (1.3543186e-05, 0.5544694, 0.012295467, 0.96429384)
decoder loss ratio: 0.000073, decoder SINDy loss  ratio: 0.001012
THRESHOLDING: 13 active coefficients
REFINEMENT
Epoch 0
   training loss 2.1868663679924794e-06, (2.0124758e-06, 0.071500786, 0.0017439052, 0.96959835)
   validation loss 3.6489766443992266e-06, (3.2103092e-06, 0.42089018, 0.004386675, 0.96959835)
decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000361
Epoch 100
   training loss 6.339595529425424e-06, (6.143587e-06, 0.047033627, 0.0019600838, 1.0054685)
   validation loss 9.146867341769394e-06, (8.655324e-06, 0.4151618, 0.0049154335, 1.0054685)
decoder loss ratio: 0.000047, decoder SINDy loss  ratio: 0.000405
Epoch 200
   training loss 6.683754236291861e-06, (6.5641425e-06, 0.03739311, 0.0011961166, 1.0103976)
   validation loss 1.0487096915312577e-05, (1.0006148e-05, 0.34957877, 0.0048094923, 1.0103976)
decoder loss ratio: 0.000054, decoder SINDy loss  ratio: 0.000396
Epoch 300
   training loss 1.4899882216923288e-06, (1.4184037e-06, 0.031911843, 0.0007158451, 1.0136901)
   validation loss 2.5158715288853273e-06, (2.2515865e-06, 0.3685416, 0.0026428513, 1.0136901)
decoder loss ratio: 0.000012, decoder SINDy loss  ratio: 0.000218
Epoch 400
   training loss 4.021569111500867e-06, (3.9061283e-06, 0.03783978, 0.0011544097, 1.0155799)
   validation loss 6.7179826146457344e-06, (6.3794946e-06, 0.42015326, 0.0033848798, 1.0155799)
decoder loss ratio: 0.000034, decoder SINDy loss  ratio: 0.000279
Epoch 500
   training loss 4.9028840294340625e-06, (4.8006686e-06, 0.034466267, 0.0010221521, 1.0177401)
   validation loss 8.58113980939379e-06, (8.161916e-06, 0.33135307, 0.0041922345, 1.0177401)
decoder loss ratio: 0.000044, decoder SINDy loss  ratio: 0.000345
Epoch 600
   training loss 1.760952545737382e-05, (1.738546e-05, 0.061393876, 0.0022406473, 1.0191777)
   validation loss 2.538961598474998e-05, (2.4438552e-05, 0.4692131, 0.009510647, 1.0191777)
decoder loss ratio: 0.000132, decoder SINDy loss  ratio: 0.000783
Epoch 700
   training loss 7.51136724375101e-07, (6.952054e-07, 0.027511714, 0.0005593133, 1.0204585)
   validation loss 1.8581163203634787e-06, (1.6414347e-06, 0.34687734, 0.0021668163, 1.0204585)
decoder loss ratio: 0.000009, decoder SINDy loss  ratio: 0.000178
Epoch 800
   training loss 3.794765461861971e-06, (3.705902e-06, 0.030422375, 0.0008886347, 1.0218682)
   validation loss 6.15150565863587e-06, (5.827001e-06, 0.31623647, 0.003245043, 1.0218682)
decoder loss ratio: 0.000031, decoder SINDy loss  ratio: 0.000267
Epoch 900
   training loss 1.0395363005955005e-06, (9.822567e-07, 0.028464219, 0.00057279604, 1.0228534)
   validation loss 1.942217068062746e-06, (1.7376153e-06, 0.30134478, 0.0020460165, 1.0228534)
decoder loss ratio: 0.000009, decoder SINDy loss  ratio: 0.000168
Epoch 1000
   training loss 6.144347480585566e-06, (6.0011225e-06, 0.04012151, 0.0014322512, 1.0240655)
   validation loss 8.532522770110518e-06, (8.084391e-06, 0.33337346, 0.004481321, 1.0240655)
decoder loss ratio: 0.000044, decoder SINDy loss  ratio: 0.000369
EXPERIMENT 5
TRAINING
Epoch 0
   training loss 0.02580421231687069, (0.025345434, 1213.7847, 4.504177, 0.83607143)
   validation loss 0.04033886268734932, (0.039097674, 1457.2731, 12.328282, 0.83607143)
decoder loss ratio: 0.211121, decoder SINDy loss  ratio: 1.015140
Epoch 100
   training loss 7.105786789907143e-05, (4.66903e-05, 0.095107935, 0.039877243, 2.0379844)
   validation loss 0.00010369316441938281, (7.2429415e-05, 0.30032727, 0.108839065, 2.0379844)
decoder loss ratio: 0.000391, decoder SINDy loss  ratio: 0.008962
Epoch 200
   training loss 2.674699317140039e-05, (8.091373e-06, 0.037287768, 0.011839194, 1.7471701)
   validation loss 3.45052540069446e-05, (1.3767785e-05, 0.086535804, 0.032657668, 1.7471701)
decoder loss ratio: 0.000074, decoder SINDy loss  ratio: 0.002689
Epoch 300
   training loss 3.0211649573175237e-05, (1.3973255e-05, 0.04363231, 0.008698396, 1.5368556)
   validation loss 3.692494647111744e-05, (1.9497535e-05, 0.10386344, 0.020588536, 1.5368556)
decoder loss ratio: 0.000105, decoder SINDy loss  ratio: 0.001695
Epoch 400
   training loss 3.421018845983781e-05, (1.9516545e-05, 0.042586505, 0.0075423084, 1.3939412)
   validation loss 4.267950862413272e-05, (2.7043021e-05, 0.12150571, 0.01697077, 1.3939412)
decoder loss ratio: 0.000146, decoder SINDy loss  ratio: 0.001397
Epoch 500
   training loss 3.4097349271178246e-05, (2.0494537e-05, 0.04338491, 0.005846497, 1.3018163)
   validation loss 4.517687193583697e-05, (3.0903182e-05, 0.13403237, 0.012555294, 1.3018163)
decoder loss ratio: 0.000167, decoder SINDy loss  ratio: 0.001034
THRESHOLDING: 33 active coefficients
Epoch 600
   training loss 2.740853960858658e-05, (1.466103e-05, 0.039659712, 0.004646256, 1.2282884)
   validation loss 2.743641016422771e-05, (1.410785e-05, 0.14294869, 0.0104567725, 1.2282884)
decoder loss ratio: 0.000076, decoder SINDy loss  ratio: 0.000861
Epoch 700
   training loss 1.9861487089656293e-05, (7.6116835e-06, 0.038108654, 0.0047911247, 1.1770692)
   validation loss 2.499107904441189e-05, (1.1939261e-05, 0.15835546, 0.012811266, 1.1770692)
decoder loss ratio: 0.000064, decoder SINDy loss  ratio: 0.001055
Epoch 800
   training loss 1.6016221707104705e-05, (4.2794795e-06, 0.036459357, 0.0042255595, 1.1314187)
   validation loss 2.0054096239618957e-05, (7.829412e-06, 0.15205067, 0.009104966, 1.1314187)
decoder loss ratio: 0.000042, decoder SINDy loss  ratio: 0.000750
Epoch 900
   training loss 1.7332646166323684e-05, (5.9370136e-06, 0.034653544, 0.0039287037, 1.1002762)
   validation loss 2.1436455426737666e-05, (9.514895e-06, 0.15438063, 0.009187982, 1.1002762)
decoder loss ratio: 0.000051, decoder SINDy loss  ratio: 0.000757
Epoch 1000
   training loss 2.0617128029698506e-05, (9.490321e-06, 0.038907837, 0.0033446497, 1.0792342)
   validation loss 2.579564170446247e-05, (1.4258439e-05, 0.15749124, 0.0074486076, 1.0792342)
decoder loss ratio: 0.000077, decoder SINDy loss  ratio: 0.000613
THRESHOLDING: 22 active coefficients
Epoch 1100
   training loss 1.4210569133865647e-05, (3.2650573e-06, 0.053785313, 0.004115993, 1.0533912)
   validation loss 1.6979278370854445e-05, (5.64439e-06, 0.16916387, 0.008009765, 1.0533912)
decoder loss ratio: 0.000030, decoder SINDy loss  ratio: 0.000660